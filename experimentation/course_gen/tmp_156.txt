/Users/rahulduggal/Documents/personal_learnings/learning-assistant-v1/experimentation/new_knowledge_base/wiki/text_files/Machine learning - Wikipedia.txt

 | f (previously) unknown properties in the data (this is the
analysis step of knowledge discovery in databases). Data mining uses many machine learning
methods, but with different goals; on the other hand, machine learning also employs data mining
methods as "unsupervised learning" or as a preprocessing step to improve learner accuracy. Much of
the confusion between these two research communities (which do often have separate conferences
and separate journals, ECML PKDD being a major exception) comes from the basic assumptions they
work with: in machine learning, performance is usually evaluated with respect to the ability to
reproduce known knowledge, while in knowledge discovery and data mining (KDD) the key task is the
discovery of previously unknown knowledge. Evaluated with respect to known knowledge, an
uninformed (unsupervised) method will easily be outperformed by other supervised methods, while in
a typical KDD task, supervised methods cannot be used due to the unavailability of training data.

Machine learning also has intimate ties to optimization: many learning problems are formulated as
minimization of some loss function on a training set of examples. Loss functions express the
discrepancy between the predictions of the model being trained and the actual problem instances (for
example, in classification, one wants to assign a label to instances, and models are trained to correctly
predict the pre-assigned labels of a set of examples).[35]

The difference between optimization and machine learning arises from the goal of generalization:
while optimization algorithms can minimize the loss on a training set, machine learning is concerned
with minimizing the loss on unseen samples. Characterizing the generalization of various learning
algorithms is an active topic of current research, especially for deep learning algorithms.

Machine learning and statistics are closely related fields in terms of methods, but distinct in their
principal goal: statistics draws population inferences from a sample, while machine learning finds
generalizable predictive patterns.[36] According to Michael I. Jordan, the ideas of machine learning,
from methodological principles to theoretical tools, have had a long pre-history in statistics.[37] He
also suggested the term data science as a placeholder to call the overall field.[37]

Conventional statistical analyses require the a priori selection of a model most suitable for the study
data set. In addition, only significant or theoretically relevant variables based on previous experience
are included for analysis. In contrast, machine learning is not built on a pre-structured model; rather,

Data mining

Generalization

Statistics

https://en.wikipedia.org/wiki/Large_language_model
https://en.wikipedia.org/wiki/DeepMind
https://en.wikipedia.org/wiki/Portable_Network_Graphics
https://en.wikipedia.org/wiki/Free_Lossless_Audio_Codec
https://en.wikipedia.org/wiki/Data_mining
https://en.wikipedia.org/wiki/Data_mining
https://en.wikipedia.org/wiki/Discovery_(observation)
https://en.wikipedia.org/wiki/Knowledge_discovery
https://en.wikipedia.org/wiki/Data_mining
https://en.wikipedia.org/wiki/Unsupervised_learning
https://en.wikipedia.org/wiki/ECML_PKDD
https://en.wikipedia.org/wiki/Mathematical_optimization
https://en.wikipedia.org/wiki/Loss_function
https://en.wikipedia.org/wiki/Generalization_(learning)
https://en.wikipedia.org/wiki/Deep_learning
https://en.wikipedia.org/wiki/Statistics
https://en.wikipedia.org/wiki/Statistical_inference
https://en.wikipedia.org/wiki/Sample_(statistics)
https://en.wikipedia.org/wiki/Michael_I._Jordan
https://en.wikipedia.org/wiki/Data_science


4/9/24, 8:12 PM Machine learning - Wikipedia

https://en.wikipedia.org/wiki/Machine_learning 5/38

the data shape the model by detecting underlying patterns. The more variables (input) used to train
the model, the more accurate the ultimate model will be.[38]

Leo Breiman distinguished two statistical modeling paradigms: data model and algorithmic model,[39]

wherein "algorithmic model" means more or less the machine learning algorithms like Random
Forest.

Some statisticians have adopted methods from machine learning, leading to a combined field that they
call statistical learning.[40]

Analytical and computational techniques derived from deep-rooted physics of disordered systems can
be extended to large-scale problems, including machine learning, e.g., to analyze the weight space of
deep neural networks.[41] Statistical physics is thus finding applications in the area of medical
diagnostics.[42]

A core objective of a learner is to generalize from its experience.[6][43] Generalization in this context is
the ability of a learning machine to perform accurately on new, unseen examples/tasks after having
experienced a learning data set. The training examples come from some generally unknown
probability distribution (considered representative of the space of occurrences) and the learner has to
build a general model about this space that enables it to produce sufficiently accurate predictions in
new cases.

The computational analysis of machine learning algorithms and their performance is a branch of
theoretical computer science known as computational learning theory via the Probably Approximately
Correct Learning (PAC) model. Because training sets are finite and the future is uncertain, learning
theory usually does not yield guarantees of the performance of algorithms. Instead, probabilistic
bounds on the performance are quite common. The biasâ€“variance decomposition is one way to
quantify generalization error.

For the best performance in the context of generalization, the complexity of the hypothesis should
match the complexity of the function underlying the data. If the hypothesis is less complex than the
function, then the model has under fitted the data. If the complexity of the model is increased in
response, then the training error decreases. But if the hypothesis is too complex, then the model is
subject to overfitting and generalization will be poorer.[44]

In addition to performance bounds, learning theorists study the time complexity and feasibility of
learning. In computational learning theory, a computation is considered feasible if it can be done in
polynomial time. There are two kinds of time complexity results: Positive results show that a certain
class of functions can be learned in polynomial time. Negative results show that certain classes cannot
be learned in polynomial time.

Statistical physics

Theory

Approaches

https://en.wikipedia.org/wiki/Leo_Breiman
https://en.wikipedia.org/wiki/Random_forest
https://en.wikipedia.org/wiki/Random_forest
https://en.wikipedia.org/wiki/Deep_neural_network
https://en.wikipedia.org/wiki/Medical_diagnostics
https://en.wikipedia.org/wiki/Medical_diagnostics
https://en.wikipedia.org/wiki/Theoretical_computer_science
https://en.wikipedia.org/wiki/Computational_learning_theory
https://en.wikipedia.org/wiki/Probably_approximately_correct_learning
https://en.wikipedia.org/wiki/Probably_approximately_correct_learning
https://en.wikipedia.org/wiki/Bias%E2%80%93variance_decomposition
https://en.wikipedia.org/wiki/Errors_and_residuals
https://en.wikipedia.org/wiki/Overfitting
https://en.wikipedia.org/wiki/Time_complexity#Polynomial_time
https://en.wikipedia.org/wiki/Time_complexity


4/9/24, 8:12 PM Machine learning - Wikipedia

https://en.wikipedia.org/wiki/Machine_learning 6/38

A support-vector machine is a
supervised learning model that
divides the data into regions
separated by a linear boundary.
Here, the linear boundary divides
the black circles from the white.

Machine learning approaches are traditionally divided into three broad categories, which correspond
to learning paradigms, depending on the nature of the "signal" or "feedback" available to the learning
system:

Supervised learning: The computer is presented with example inputs and their desired outputs,
given by a "teacher", and the goal is to learn a general rule that maps inputs to outputs.
Unsupervised learning: No labels are given to the learning algorithm, leaving it on its own to find
structure in its input. Unsupervised learning can be a goal in itself (discovering hidden patterns in
data) or a means towards an end (feature learning).
Reinforcement learning: A computer program interacts with a dynamic environment in which it
must perform a certain goal (such as driving a vehicle or playing a game against an opponent). As
it navigates its problem space, the program is provided feedback that's analogous to rewards,
which it tries to maximize.[6]

Although each algorithm has advantages and limitations, no single algorithm works for all
problems.[45][46][47]

Supervised learning algorithms build a mathematical model of a
set of data that contains both the inputs and the desired
outputs.[48] The data is known as training data, and consists of a
set of training examples. Each training example has one or more
inputs and the desired output, also known as a supervisory signal.
In the mathematical model, each training example is represented
by an array or vector, sometimes called a feature vector, and the
training data is represented by a matrix. Through iterative
optimization of an objective function, supervised learning
algorithms learn a function that can be used to predict the output
associated with new inputs.[49] An optimal function allows the
algorithm to correctly determine the output for inputs that were
not a part of the training data. An algorithm that improves the
accuracy of its outputs or predictions over time is said to have
learned to perform that task.[19]

Types of supervised-learning algorithms include active learning,
classification and regression.[50] Classification algorithms are used
when the outputs are restricted to a limited set of values, and
regression algorithms are used when the outputs may have any numerical value within a range. As an
example, for a classification algorithm that filters emails, the input would be an incoming email, and
the output would be the name of the folder in which to file the email.

Supervised learning

https://en.wikipedia.org/wiki/File:Svm_max_sep_hyperplane_with_margin.png
https://en.wikipedia.org/wiki/File:Svm_max_sep_hyperplane_with_margin.png
https://en.wikipedia.org/wiki/Support-vector_machine
https://en.wikipedia.org/wiki/Linear_classifier
https://en.wikipedia.org/wiki/Supervised_learning
https://en.wikipedia.org/wiki/Map_(mathematics)
https://en.wikipedia.org/wiki/Unsupervised_learning
https://en.wikipedia.org/wiki/Feature_learning
https://en.wikipedia.org/wiki/Reinforcement_learning
https://en.wikipedia.org/wiki/Autonomous_car
https://en.wikipedia.org/wiki/Training_data
https://en.wikipedia.org/wiki/Array_data_structure
https://en.wikipedia.org/wiki/Feature_vector
https://en.wikipedia.org/wiki/Matrix_(mathematics)
https://en.wikipedia.org/wiki/Mathematical_optimization#Computational_optimization_techniques
https://en.wikipedia.org/wiki/Mathematical_optimization#Computational_optimization_techniques
https://en.wikipedia.org/wiki/Loss_function
https://en.wikipedia.org/wiki/Active_learning_(machine_learning)
https://en.wikipedia.org/wiki/Statistical_classification
https://en.wikipedia.org/wiki/Regression_analysis


4/9/24, 8:12 PM Machine learning - Wikipedia

https://en.wikipedia.org/wiki/Machine_learning 7/38

Clustering via Large Indel Permuted Slopes, CLIPS, turns the alignment image into a
learning regression problem. The varied slope (b) estimates between each pair of DNA
segments enables to identify segments sharing the same set of indels.

Similarity learning is an area of supervised machine learning closely related to regression and
classification, but the goal is to learn from examples using a similarity function that measures how
similar or related two objects are. It has applications in ranking, recommendation systems, visual
identity tracking, face verification, and speaker verification.

Unsupervised learning algorithms find structures in data that has not been labeled, classified or
categorized. Instead of responding to feedback, unsupervised learning algorithms identify
commonalities in the data and react based on the presence or absence of such commonalities in each
new piece of data. Central applications of unsupervised machine learning include clustering,
dimensionality reduction,[8] and density estimation.[51] Unsupervised learning algorithms also
streamlined the process of identifying large indel based haplotypes of a gene of interest from pan-
genome.[52]

Cluster analysis is the assignment of a set of observations into subsets (called clusters) so that
observations within the same cluster are similar according to one or more predesignated criteria,
while observations drawn from different clusters are dissimilar. Different clustering techniques make
different assumptions on the structure of the data, often defined by some similarity metric and
evaluated, for example, by internal compactness, or the similarity between members of the same
cluster, and separation, the difference between clusters. Other methods are based on estimated
density and graph connectivity.

Semi-supervised learning falls between unsupervised learning (without any labeled training data) and
supervised learning (with completely labeled training data). Some of the training examples are
missing training labels, yet many machine-learning researchers have found that unlabeled data, when
used in conjunction with a small amount of labeled data, can produce a considerable improvement in
learning accuracy.

In weakly supervised learning, the training labels are noisy, limited, or imprecise; however, these
labels are often cheaper to obtain, resulting in larger effective training sets.[53]

Unsupervised learning

Semi-supervised learning

Reinforcement learning

https://en.wikipedia.org/wiki/File:CLIPS.jpg
https://en.wikipedia.org/wiki/File:CLIPS.jpg
https://doi.org/10.1101/2023.02.11.527743
https://en.wikipedia.org/wiki/Similarity_learning
https://en.wikipedia.org/wiki/Ranking
https://en.wikipedia.org/wiki/Recommender_system
https://en.wikipedia.org/wiki/Dimensionality_reduction
https://en.wikipedia.org/wiki/Density_estimation
https://en.wikipedia.org/wiki/Indel
https://en.wikipedia.org/wiki/Haplotype
https://en.wikipedia.org/wiki/Pan-genome
https://en.wikipedia.org/wiki/Pan-genome
https://en.wikipedia.org/wiki/Unsupervised_learning
https://en.wikipedia.org/wiki/Supervised_learning
https://en.wikipedia.org/wiki/Weak_supervision


4/9/24, 8:12 PM Machine learning - Wikipedia

https://en.wikipedia.org/wiki/Machine_learning 8/38

Reinforcement learning is an area of machine learning concerned with how software agents ought to
take actions in an environment so as to maximize some notion of cumulative reward. Due to its
generality, the field is studied in many other disciplines, such as game theory, control theory,
operations research, information theory, simulation-