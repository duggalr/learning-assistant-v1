/Users/rahulduggal/Documents/personal_learnings/learning-assistant-v1/experimentation/new_knowledge_base/wiki/text_files/Machine learning - Wikipedia.txt

 | many caveats to these beliefs functions when compared to
Bayesian approaches in order to incorporate ignorance and Uncertainty quantification. These belief
function approaches that are implemented within the machine learning domain typically leverage a
fusion approach of various ensemble methods to better handle the learner's decision boundary, low
samples, and ambiguous class issues that standard machine learning approach tend to have difficulty
resolving.[3][5][10] However, the computational complexity of these algorithms are dependent on the
number of propositions (classes), and can lead a much higher computation time when compared to
other machine learning approaches.

Typically, machine learning models require a high quantity of reliable data in order for the models to
perform accurate predictions. When training a machine learning model, machine learning engineers
need to target and collect a large and representative sample of data. Data from the training set can be
as varied as a corpus of text, a collection of images, sensor data, and data collected from individual
users of a service. Overfitting is something to watch out for when training a machine learning model.
Trained models derived from biased or non-evaluated data can result in skewed or undesired
predictions. Bias models may result in detrimental outcomes thereby furthering the negative impacts
on society or objectives. Algorithmic bias is a potential result of data not being fully prepared for
training. Machine learning ethics is becoming a field of study and notably be integrated within
machine learning engineering teams.

Federated learning is an adapted form of distributed artificial intelligence to training machine
learning models that decentralizes the training process, allowing for users' privacy to be maintained
by not needing to send their data to a centralized server. This also increases efficiency by
decentralizing the training process to many devices. For example, Gboard uses federated machine
learning to train search query prediction models on users' mobile phones without having to send
individual searches back to Google.[93]

There are many applications for machine learning, including:

Agriculture
Anatomy
Adaptive website
Affective computing
Astronomy
Automated decision-making
Banking
Behaviorism
Bioinformatics
Brain–machine interfaces
Cheminformatics

Citizen Science
Climate Science
Computer networks
Computer vision
Credit-card fraud detection
Data quality
DNA sequence classification
Economics
Financial market analysis[94]

General game playing
Handwriting recognition

Training models

Federated learning

Applications

https://en.wikipedia.org/wiki/Uncertainty_quantification
https://en.wikipedia.org/wiki/Ensemble_methods
https://en.wikipedia.org/wiki/Decision_boundary
https://en.wikipedia.org/wiki/Sample_(statistics)
https://en.wikipedia.org/wiki/Corpus_of_text
https://en.wikipedia.org/wiki/Sensor
https://en.wikipedia.org/wiki/Overfitting
https://en.wikipedia.org/wiki/Algorithmic_bias
https://en.wikipedia.org/wiki/Distributed_artificial_intelligence
https://en.wikipedia.org/wiki/Gboard
https://en.wikipedia.org/wiki/Google
https://en.wikipedia.org/wiki/Precision_agriculture
https://en.wikipedia.org/wiki/Computational_anatomy
https://en.wikipedia.org/wiki/Adaptive_website
https://en.wikipedia.org/wiki/Affective_computing
https://en.wikipedia.org/wiki/Astroinformatics
https://en.wikipedia.org/wiki/Automated_decision-making
https://en.wikipedia.org/wiki/Banking
https://en.wikipedia.org/wiki/Behaviorism
https://en.wikipedia.org/wiki/Bioinformatics
https://en.wikipedia.org/wiki/Brain%E2%80%93computer_interface
https://en.wikipedia.org/wiki/Cheminformatics
https://en.wikipedia.org/wiki/Citizen_Science
https://en.wikipedia.org/wiki/Climate_Science
https://en.wikipedia.org/wiki/Network_simulation
https://en.wikipedia.org/wiki/Computer_vision
https://en.wikipedia.org/wiki/Credit-card_fraud
https://en.wikipedia.org/wiki/Data_quality
https://en.wikipedia.org/wiki/DNA_sequence
https://en.wikipedia.org/wiki/Computational_economics
https://en.wikipedia.org/wiki/Financial_market
https://en.wikipedia.org/wiki/General_game_playing
https://en.wikipedia.org/wiki/Handwriting_recognition


4/9/24, 8:12 PM Machine learning - Wikipedia

https://en.wikipedia.org/wiki/Machine_learning 16/38

Healthcare
Information retrieval
Insurance
Internet fraud detection
Knowledge graph embedding
Linguistics
Machine learning control
Machine perception
Machine translation
Marketing
Medical diagnosis
Natural language processing
Natural language understanding
Online advertising
Optimization

Recommender systems
Robot locomotion
Search engines
Sentiment analysis
Sequence mining
Software engineering
Speech recognition
Structural health monitoring
Syntactic pattern recognition
Telecommunication
Theorem proving
Time-series forecasting
Tomographic reconstruction[95]

User behavior analytics

In 2006, the media-services provider Netflix held the first "Netflix Prize" competition to find a
program to better predict user preferences and improve the accuracy of its existing Cinematch movie
recommendation algorithm by at least 10%. A joint team made up of researchers from AT&T Labs-
Research in collaboration with the teams Big Chaos and Pragmatic Theory built an ensemble model to
win the Grand Prize in 2009 for $1 million.[96] Shortly after the prize was awarded, Netflix realized
that viewers' ratings were not the best indicators of their viewing patterns ("everything is a
recommendation") and they changed their recommendation engine accordingly.[97] In 2010 The Wall
Street Journal wrote about the firm Rebellion Research and their use of machine learning to predict
the financial crisis.[98] In 2012, co-founder of Sun Microsystems, Vinod Khosla, predicted that 80% of
medical doctors jobs would be lost in the next two decades to automated machine learning medical
diagnostic software.[99] In 2014, it was reported that a machine learning algorithm had been applied
in the field of art history to study fine art paintings and that it may have revealed previously
unrecognized influences among artists.[100] In 2019 Springer Nature published the first research book
created using machine learning.[101] In 2020, machine learning technology was used to help make
diagnoses and aid researchers in developing a cure for COVID-19.[102] Machine learning was recently
applied to predict the pro-environmental behavior of travelers.[103] Recently, machine learning
technology was also applied to optimize smartphone's performance and thermal behavior based on
the user's interaction with the phone.[104][105][106] When applied correctly, machine learning
algorithms (MLAs) can utilize a wide range of company characteristics to predict stock returns
without overfitting. By employing effective feature engineering and combining forecasts, MLAs can
generate results that far surpass those obtained from basic linear techniques like OLS.[107]

Although machine learning has been transformative in some fields, machine-learning programs often
fail to deliver expected results.[108][109][110] Reasons for this are numerous: lack of (suitable) data, lack
of access to the data, data bias, privacy problems, badly chosen tasks and algorithms, wrong tools and
people, lack of resources, and evaluation problems.[111]

Limitations

https://en.wikipedia.org/wiki/Artificial_intelligence_in_healthcare
https://en.wikipedia.org/wiki/Information_retrieval
https://en.wikipedia.org/wiki/Insurance
https://en.wikipedia.org/wiki/Internet_fraud
https://en.wikipedia.org/wiki/Knowledge_graph_embedding
https://en.wikipedia.org/wiki/Computational_linguistics
https://en.wikipedia.org/wiki/Machine_learning_control
https://en.wikipedia.org/wiki/Machine_perception
https://en.wikipedia.org/wiki/Machine_translation
https://en.wikipedia.org/wiki/Marketing
https://en.wikipedia.org/wiki/Automated_medical_diagnosis
https://en.wikipedia.org/wiki/Natural_language_processing
https://en.wikipedia.org/wiki/Natural-language_understanding
https://en.wikipedia.org/wiki/Online_advertising
https://en.wikipedia.org/wiki/Mathematical_optimization
https://en.wikipedia.org/wiki/Recommender_system
https://en.wikipedia.org/wiki/Robot_locomotion
https://en.wikipedia.org/wiki/Search_engines
https://en.wikipedia.org/wiki/Sentiment_analysis
https://en.wikipedia.org/wiki/Sequence_mining
https://en.wikipedia.org/wiki/Software_engineering
https://en.wikipedia.org/wiki/Speech_recognition
https://en.wikipedia.org/wiki/Structural_health_monitoring
https://en.wikipedia.org/wiki/Syntactic_pattern_recognition
https://en.wikipedia.org/wiki/Telecommunication
https://en.wikipedia.org/wiki/Automated_theorem_proving
https://en.wikipedia.org/wiki/Time_series
https://en.wikipedia.org/wiki/Tomographic_reconstruction
https://en.wikipedia.org/wiki/User_behavior_analytics
https://en.wikipedia.org/wiki/Netflix
https://en.wikipedia.org/wiki/Netflix_Prize
https://en.wikipedia.org/wiki/AT%26T_Labs
https://en.wikipedia.org/wiki/Ensemble_Averaging
https://en.wikipedia.org/wiki/Sun_Microsystems
https://en.wikipedia.org/wiki/Vinod_Khosla
https://en.wikipedia.org/wiki/Springer_Nature
https://en.wikipedia.org/wiki/Overfitting
https://en.wikipedia.org/wiki/Ordinary_least_squares


4/9/24, 8:12 PM Machine learning - Wikipedia

https://en.wikipedia.org/wiki/Machine_learning 17/38

The "black box theory" poses another yet significant challenge. Black box refers to a situation where
the algorithm or the process of producing an output is entirely opaque, meaning that even the coders
of the algorithm cannot audit the pattern that the machine extracted out of the data.[112] The House of
Lords Select Committee, which claimed that such an “intelligence system” that could have a
“substantial impact on an individual’s life” would not be considered acceptable unless it provided “a
full and satisfactory explanation for the decisions” it makes.[112]

In 2018, a self-driving car from Uber failed to detect a pedestrian, who was killed after a collision.[113]

Attempts to use machine learning in healthcare with the IBM Watson system failed to deliver even
after years of time and billions of dollars invested.[114][115] Microsoft's Bing Chat chatbot has been
reported to produce hostile and offensive response against its users.[116]

Machine learning has been used as a strategy to update the evidence related to a systematic review
and increased reviewer burden related to the growth of biomedical literature. While it has improved
with training sets, it has not yet developed sufficiently to reduce the workload burden without limiting
the necessary sensitivity for the findings research themselves.[117]

Machine learning approaches in particular can suffer from different data biases. A machine learning
system trained specifically on current customers may not be able to predict the needs of new customer
groups that are not represented in the training data. When trained on human-made data, machine
learning is likely to pick up the constitutional and unconscious biases already present in society.[118]

Language models learned from data have been shown to contain human-like biases.[119][120] In an
experiment carried out by ProPublica, an investigative journalism organization, a machine learning
algorithm's insight towards the recidivism rates among prisoners falsely flagged “black defendants
high risk twice as often as white defendants.”[121] In 2015, Google photos would often tag black people
as gorillas,[121] and in 2018 this still was not well resolved, but Google reportedly was still using the
workaround to remove all gorillas from the training data, and thus was not able to recognize real
gorillas at all.[122] Similar issues with recognizing non-white people have been found in many other
systems.[123] In 2016, Microsoft tested Tay, a chatbot that learned from Twitter, and it quickly picked
up racist and sexist language.[124]

Because of such challenges, the effective use of machine learning may take longer to be adopted in
other domains.[125] Concern for fairness in machine learning, that is, reducing bias in machine
learning and propelling its use for human good is increasingly expressed by artificial intelligence
scientists, including Fei-Fei Li, who reminds engineers that "There's nothing artificial about AI...It's
inspired by people, it's created by people, and—most importantly—it impacts people. It is a powerful
tool we are only just beginning to understand, and that is a profound responsibility."[126]

Explainable AI (XAI), or Interpretable AI, or Explainable Machine Learning (XML), is artificial
intelligence (AI) in which humans can understand the decisions or predictions made by the AI.[127] It
contrasts with the "black box" concept in machine learning where even its designers cannot explain

Bias

Explainability

https://en.wikipedia.org/wiki/Black_box
https://en.wikipedia.org/wiki/Uber
https://en.wikipedia.org/wiki/Watson_(computer)
https://en.wikipedia.org/wiki/Bing_Chat
https://en.wikipedia.org/wiki/ProPublica
https://en.wikipedia.org/wiki/Investigative_journalism
https://en.wikipedia.org/wiki/Tay_(chatbot)
https://en.wikipedia.org/wiki/Chatbot
https://en.wikipedia.org/wiki/Fairness_(machine_learning)
https://en.wikipedia.org/wiki/Fei-Fei_Li


4/9/24, 8:12 PM Machine learning - Wikipedia

https://en.wikipedia.org/wiki/Machine_learning 18/38

The blue line could be an example
of overfitting a linear function due to
random noise.

why an AI arrived at a specific decision.[128] By refining the mental models of users of AI-powered
systems and dismantling their misconceptions, XAI promises to help users perform more effectively.
XAI may be an implementation of the social right to explanation.

Settling on a bad, overly complex theory gerrymandered to fit all
the past training data is known as overfitting. Many systems
attempt to reduce overfitting by rewarding a theory in accordance
with how well it fits the data but penalizing the theory in
accordance with how complex the theory is.[129]

Learners can also disappoint by "learning the wrong lesson". A toy
example is that an image classifier trained only on pictures of
brown horses and black cats might conclude that all brown
patches are likely to be horses.[130] A real-world example is that,
unlike humans, current image classifiers often do not primarily make judgments from the spatial
relationship between components of the picture, and they learn relationships between pixels that
humans are oblivious to, but that still correlate with images of certain types of real objects. Modifying
these patterns on a legitimate image can result in "adversarial" images that the system
misclassifies.[131][132]

Adversarial vulnerabilities can also result in nonlinear systems, or from non-pattern perturbations.
For some systems, it is possible to change the output by only changing a single adversarially chosen
pixel.[133] Machine learning models are often vulnerable to manipulation and