##Instructions:
You will be given a student's course outline, along with the specific module the student is currently working on.
Your goal is to generate course notes ONLY ON THE CURRENT MODULE the student is working on.
The goal of the course notes will be to help the student develop a strong understanding of that topic.

Your course notes must be generated such that it is specific for the student, given their goals and background.
The notes should be generated such that, it is very engaging and easy for the student to understand the material.
Please ensure your course notes for the module are as DETAILED AS POSSIBLE. The more detail, the better for the student.

DO NOT GENERATE ANY NOTES FOR FUTURE MODULES. ONLY FOCUS ON THE CURRENT MODULE.
As mentioned below, to help you generate detailed notes, you will be given additional, relevant supplementary material from different textbooks and wikipedia.
Please use this supplementary material for your course note generation.
Please note that your course notes will be the primary resource for the student, so ensure they are very detailed, rich with examples.

Below, you will be given 4 critical pieces of information:
- The student's goals, what they want to learn, and their background.
- The outline of the course the student is currently taking.
- The specific topic to focus your course notes on.
- Additional supplementary material on that topic, which you can leverage to help you generate the course notes.

Your response MUST BE OUTPUTED IN JSON FORMAT, containing the following key:
- "course_notes"
    - This will be the course notes IN MARKDOWN FORMAT, which will be presented to the student.
    - Please ensure at the beginning of your markdown, you include the Current Module Name and SubTopics that will be covered, before you include your notes.

##Student Goals/Background Information
The student wants to learn the foundations of AI, specifically Machine Learning and Deep Learning. They also want to apply this knowledge to real-world applications using LLMs such as GPT.

##Course Outline
Course Name:
Introduction to Artificial Intelligence and Machine Learning

Course Description:
Module 1: Introduction to Artificial Intelligence
- What is Artificial Intelligence?
- Overview of AI applications
- Ethics and impact of AI

Module 2: Fundamentals of Machine Learning
- Introduction to machine learning
- Supervised, unsupervised, and reinforcement learning
- Training and testing models

Module 3: Neural Networks and Deep Learning
- Understanding neural networks
- Deep learning concepts
- Building and training neural networks

Module 4: AI Applications
- Real-world applications of AI
- Case studies
- Project planning

Module 5: Large Language Models and GPT
- Overview of large language models like GPT
- Understanding GPT-3
- Practical applications of GPT

Module 6: Building AI Applications with GPT API
- Introduction to GPT API
- Implementing GPT API in projects
- Developing a simple application using GPT API


##Current Week Topic Information
Module 1: Introduction to Artificial Intelligence
- What is Artificial Intelligence?

##Supplementary Material
Artificial intelligence - Wikipedia

4/9/24, 10:28 AM Artificial intelligence - Wikipedia

https://en.wikipedia.org/wiki/Artificial_intelligence 1/56

Artificial intelligence
Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly
computer systems. It is a field of research in computer science that develops and studies methods and
software which enable machines to perceive their environment and uses learning and intelligence to
take actions that maximize their chances of achieving defined goals.[1] Such machines may be called
AIs.

AI technology is widely used throughout industry, government, and science. Some high-profile
applications include advanced web search engines (e.g., Google Search); recommendation systems
(used by YouTube, Amazon, and Netflix); interacting via human speech (e.g., Google Assistant, Siri,
and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI
art); and superhuman play and analysis in strategy games (e.g., chess and Go).[2] However, many AI
applications are not perceived as AI: "A lot of cutting edge AI has filtered into general applications,
often without being called AI because once something becomes useful enough and common enough
it's not labeled AI anymore."[3][4]

Alan Turing was the first person to conduct substantial research in the field that he called machine
intelligence.[5] Artificial intelligence was founded as an academic discipline in 1956.[6] The field went
through multiple cycles of optimism,[7][8] followed by periods of disappointment and loss of funding,
known as AI winter.[9][10] Funding and interest vastly increased after 2012 when deep learning
surpassed all previous AI techniques,[11] and after 2017 with the transformer architecture.[12] This led
to the AI boom of the early 2020s, with companies, universities, and laboratories overwhelmingly
based in the United States pioneering significant advances in artificial intelligence.[13]

The growing use of artificial intelligence in the 21st century is influencing a societal and economic
shift towards increased automation, data-driven decision-making, and the integration of AI systems
into various economic sectors and areas of life, impacting job markets, healthcare, government,
industry, and education. This raises questions about the long-term effects, ethical implications, and
risks of AI, prompting discussions about regulatory policies to ensure the safety and benefits of the
technology.

The various sub-fields of AI research are centered around particular goals and the use of particular
tools. The traditional goals of AI research include reasoning, knowledge representation, planning,
learning, natural language processing, perception, and support for robotics.[a] General intelligence—
the ability to complete any task performable by a human on an at least equal level—is among the
field's long-term goals.[14]

https://en.wikipedia.org/wiki/Main_Page
https://en.wikipedia.org/wiki/Intelligence
https://en.wikipedia.org/wiki/Machine
https://en.wikipedia.org/wiki/Computer_systems
https://en.wikipedia.org/wiki/Field_of_research
https://en.wikipedia.org/wiki/Computer_science
https://en.wikipedia.org/wiki/Machine_perception
https://en.wikipedia.org/wiki/Machine_learning
https://en.wikipedia.org/wiki/Applications_of_artificial_intelligence
https://en.wikipedia.org/wiki/Artificial_intelligence_in_industry
https://en.wikipedia.org/wiki/Artificial_intelligence_in_government
https://en.wikipedia.org/wiki/Web_search_engine
https://en.wikipedia.org/wiki/Google_Search
https://en.wikipedia.org/wiki/Recommender_system
https://en.wikipedia.org/wiki/YouTube
https://en.wikipedia.org/wiki/Amazon_(company)
https://en.wikipedia.org/wiki/Netflix
https://en.wikipedia.org/wiki/Natural-language_understanding
https://en.wikipedia.org/wiki/Google_Assistant
https://en.wikipedia.org/wiki/Siri
https://en.wikipedia.org/wiki/Amazon_Alexa
https://en.wikipedia.org/wiki/Autonomous_vehicles
https://en.wikipedia.org/wiki/Waymo
https://en.wikipedia.org/wiki/Generative_artificial_intelligence
https://en.wikipedia.org/wiki/Computational_creativity
https://en.wikipedia.org/wiki/ChatGPT
https://en.wikipedia.org/wiki/AI_art
https://en.wikipedia.org/wiki/AI_art
https://en.wikipedia.org/wiki/Superintelligence
https://en.wikipedia.org/wiki/Strategy_game
https://en.wikipedia.org/wiki/Chess
https://en.wikipedia.org/wiki/Go_(game)
https://en.wikipedia.org/wiki/AI_effect
https://en.wikipedia.org/wiki/Alan_Turing
https://en.wikipedia.org/wiki/AI_winter
https://en.wikipedia.org/wiki/Deep_learning
https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)
https://en.wikipedia.org/wiki/AI_boom
https://en.wikipedia.org/wiki/Advances_in_artificial_intelligence
https://en.wikipedia.org/wiki/AI_era
https://en.wikipedia.org/wiki/AI_era
https://en.wikipedia.org/wiki/Data-driven_decision-making
https://en.wikipedia.org/wiki/Artificial_intelligence_systems_integration
https://en.wikipedia.org/wiki/Workplace_impact_of_artificial_intelligence
https://en.wikipedia.org/wiki/Artificial_intelligence_in_healthcare
https://en.wikipedia.org/wiki/Artificial_intelligence_in_education
https://en.wikipedia.org/wiki/AI_aftermath_scenarios
https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence
https://en.wikipedia.org/wiki/AI_risk
https://en.wikipedia.org/wiki/Regulation_of_artificial_intelligence
https://en.wikipedia.org/wiki/AI_safety
https://en.wikipedia.org/wiki/AI_safety
https://en.wikipedia.org/wiki/Automated_reasoning
https://en.wikipedia.org/wiki/Knowledge_representation
https://en.wikipedia.org/wiki/Automated_planning_and_scheduling
https://en.wikipedia.org/wiki/Machine_learning
https://en.wikipedia.org/wiki/Natural_language_processing
https://en.wikipedia.org/wiki/Robotics
https://en.wikipedia.org/wiki/Artificial_general_intelligence


4/9/24, 10:28 AM Artificial intelligence - Wikipedia

https://en.wikipedia.org/wiki/Artificial_intelligence 2/56

An ontology represents knowledge as a set
of concepts within a domain and the
relationships between those concepts.

To reach these goals, AI researchers have adapted and integrated a wide range of techniques,
including search and mathematical optimization, formal logic, artificial neural networks, and methods
based on statistics, operations research, and economics.[b] AI also draws upon psychology, linguistics,
philosophy, neuroscience, and other fields.[15]

The general problem of simulating (or creating) intelligence has been broken into sub-problems.
These consist of particular traits or capabilities that researchers expect an intelligent system to
display. The traits described below have received the most attention and cover the scope of AI
research.[a]

Early researchers developed algorithms that imitated step-by-step reasoning that humans use when
they solve puzzles or make logical deductions.[16] By the late 1980s and 1990s, methods were
developed for dealing with uncertain or incomplete information, employing concepts from probability
and economics.[17]

Many of these algorithms are insufficient for solving large reasoning problems because they
experience a "combinatorial explosion": they became exponentially slower as the problems grew
larger.[18] Even humans rarely use the step-by-step deduction that early AI research could model.
They solve most of their problems using fast, intuitive judgments.[19] Accurate and efficient reasoning
is an unsolved problem.

Knowledge representation and knowledge engineering[20]

allow AI programs to answer questions intelligently and
make deductions about real-world facts. Formal knowledge
representations are used in content-based indexing and
retrieval,[21] scene interpretation,[22] clinical decision
support,[23] knowledge discovery (mining "interesting" and
actionable inferences from large databases),[24] and other
areas.[25]

A knowledge base is a body of knowledge represented in a
form that can be used by a program. An ontology is the set of
objects, relations, concepts, and properties used by a
particular domain of knowledge.[26] Knowledge bases need
to represent things such as: objects, properties, categories
and relations between objects;[27] situations, events, states
and time;[28] causes and effects;[29] knowledge about
knowledge (what we know about what other people

Goals

Reasoning and problem solving

Knowledge representation

https://en.wikipedia.org/wiki/File:General_Formal_Ontology.svg
https://en.wikipedia.org/wiki/File:General_Formal_Ontology.svg
https://en.wikipedia.org/wiki/State_space_search
https://en.wikipedia.org/wiki/Mathematical_optimization
https://en.wikipedia.org/wiki/Logic#Formal_logic
https://en.wikipedia.org/wiki/Artificial_neural_network
https://en.wikipedia.org/wiki/Statistics
https://en.wikipedia.org/wiki/Operations_research
https://en.wikipedia.org/wiki/Economics
https://en.wikipedia.org/wiki/Psychology
https://en.wikipedia.org/wiki/Linguistics
https://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence
https://en.wikipedia.org/wiki/Neuroscience
https://en.wikipedia.org/wiki/Deductive_reasoning
https://en.wikipedia.org/wiki/Uncertainty
https://en.wikipedia.org/wiki/Probability
https://en.wikipedia.org/wiki/Economics
https://en.wikipedia.org/wiki/Knowledge_representation
https://en.wikipedia.org/wiki/Knowledge_engineering
https://en.wikipedia.org/wiki/Database
https://en.wikipedia.org/wiki/Knowledge_base
https://en.wikipedia.org/wiki/Ontology_(information_science)
https://en.wikipedia.org/wiki/Knowledge_base
https://en.wikipedia.org/wiki/Ontology_(information_science)


4/9/24, 10:28 AM Artificial intelligence - Wikipedia

https://en.wikipedia.org/wiki/Artificial_intelligence 3/56

know);[30] default reasoning (things that humans assume are true until they are told differently and
will remain true even when other facts are changing);[31] and many other aspects and domains of
knowledge.

Among the most difficult problems in knowledge representation are: the breadth of commonsense
knowledge (the set of atomic facts that the average person knows is enormous);[32] and the sub-
symbolic form of most commonsense knowledge (much of what people know is not represented as
"facts" or "statements" that they could express verbally).[19] There is also the difficulty of knowledge
acquisition, the problem of obtaining knowledge for AI applications.[c]

An "agent" is anything that perceives and takes actions in the world. A rational agent has goals or
preferences and takes actions to make them happen.[d][35] In automated planning, the agent has a
specific goal.[36] In automated decision making, the agent has preferences—there are some situations
it would prefer to be in, and some situations it is trying to avoid. The decision making agent assigns a
number to each situation (called the "utility") that measures how much the agent prefers it. For each
possible action, it can calculate the "expected utility": the utility of all possible outcomes of the action,
weighted by the probability that the outcome will occur. It can then choose the action with the
maximum expected utility.[37]

In classical planning, the agent knows exactly what the effect of any action will be.[38] In most real-
world problems, however, the agent may not be certain about the situation they are in (it is
"unknown" or "unobservable") and it may not know for certain what will happen after each possible
action (it is not "deterministic"). It must choose an action by making a probabilistic guess and then
reassess the situation to see if the action worked.[39]

In some problems, the agent's preferences may be uncertain, especially if there are other agents or
humans involved. These can be learned (e.g., with inverse reinforcement learning) or the agent can
seek information to improve its preferences.[40] Information value theory can be used to weigh the
value of exploratory or experimental actions.[41] The space of possible future actions and situations is
typically intractably large, so the agents must take actions and evaluate situations while being
uncertain what the outcome will be.

A Markov decision process has a transition model that describes the probability that a particular
action will change the state in a particular way, and a reward function that supplies the utility of each
state and the cost of each action. A policy associates a decision with each possible state. The policy
could be calculated (e.g., by iteration), be heuristic, or it can be learned.[42]

Game theory describes rational behavior of multiple interacting agents, and is used in AI programs
that make decisions that involve other agents.[43]

Machine learning is the study of programs that can improve their performance on a given task
automatically.[44] It has been a part of AI from the beginning.[e]

Planning and decision making

Learning

https://en.wikipedia.org/wiki/Default_reasoning
https://en.wikipedia.org/wiki/Knowledge_acquisition
https://en.wikipedia.org/wiki/Knowledge_acquisition
https://en.wikipedia.org/wiki/Rational_agent
https://en.wikipedia.org/wiki/Automated_planning_and_scheduling
https://en.wikipedia.org/wiki/Automated_decision_making
https://en.wikipedia.org/wiki/Utility_(economics)
https://en.wikipedia.org/wiki/Expected_utility
https://en.wikipedia.org/wiki/Utility
https://en.wikipedia.org/wiki/Automated_planning_and_scheduling#classical_planning
https://en.wikipedia.org/wiki/Inverse_reinforcement_learning
https://en.wikipedia.org/wiki/Information_value_theory
https://en.wikipedia.org/wiki/Intractable_problem
https://en.wikipedia.org/wiki/Markov_decision_process
https://en.wikipedia.org/wiki/Finite-state_machine
https://en.wikipedia.org/wiki/Reward_function
https://en.wikipedia.org/wiki/Reinforcement_learning#Policy
https://en.wikipedia.org/wiki/Policy_iteration
https://en.wikipedia.org/wiki/Heuristic
https://en.wikipedia.org/wiki/Game_theory
https://en.wikipedia.org/wiki/Machine_learning


4/9/24, 10:28 AM Artificial intelligence - Wikipedia

https://en.wikipedia.org/wiki/Artificial_intelligence 4/56

There are several kinds of machine learning. Unsupervised learning analyzes a stream of data and
finds patterns and makes predictions without any other guidance.[47] Supervised learning requires a
human to label the input data first, and comes in two main varieties: classification (where the program
must learn to predict what category the input belongs in) and regression (where the program must
deduce a numeric function based on numeric input).[48]

In reinforcement learning the agent is rewarded for good responses and punished for bad ones. The
agent learns to choose responses that are classified as "good".[49] Transfer learning is when the
knowledge gained from one problem is applied to a new problem.[50] Deep learning is a type of
machine learning that runs inputs through biologically inspired artificial neural networks for all of
these types of learning.[51]

Computational learning theory can assess learner
dwritten digits, the first of
many successful applications of neural networks.[273]

AI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal
mathematical methods and by finding specific solutions to specific problems. This "narrow" and
"formal" focus allowed researchers to produce verifiable results and collaborate with other fields (such
as statistics, economics and mathematics).[274] By 2000, solutions developed by AI researchers were
being widely used, although in the 1990s they were rarely described as "artificial intelligence".[275]

However, several academic researchers became concerned that AI was no longer pursuing its original
goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the
subfield of artificial general intelligence (or "AGI"), which had several well-funded institutions by the
2010s.[14]

Deep learning began to dominate industry benchmarks in 2012 and was adopted throughout the
field.[11] For many specific tasks, other methods were abandoned.[x] Deep learning's success was based
on both hardware improvements (faster computers,[277] graphics processing units, cloud
computing[278]) and access to large amounts of data[279] (including curated datasets,[278] such as
ImageNet). Deep learning's success led to an enormous increase in interest and funding in AI.[y] The
amount of machine learning research (measured by total publications) increased by 50% in the years
2015–2019.[239]

In 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine
learning conferences, publications vastly increased, funding became available, and many researchers
re-focussed their careers on these issues. The alignment problem became a serious field of academic
study.[224]

In the late teens and early 2020s, AGI companies began to deliver programs that created enormous
interest. In 2015, AlphaGo, developed by DeepMind, beat the world champion Go player. The program
was taught only the rules of the game and developed strategy by itself. GPT-3 is a large language
model that was released in 2020 by OpenAI and is capable of generating high-quality human-like
text.[280] These programs, and others, inspired an aggressive AI boom, where large companies began
investing billions in AI research. According to 'AI Impacts', about $50 billion annually was invested in
"AI" around 2022 in the U.S. alone and about 20% of new US Computer Science PhD graduates have
specialized in "AI".[281] About 800,000 "AI"-related US job openings existed in 2022.[282]

Alan Turing wrote in 1950 "I propose to consider the question 'can machines think'?"[283] He advised
changing the question from whether a machine "thinks", to "whether or not it is possible for
machinery to show intelligent behaviour".[283] He devised the Turing test, which measures the ability

Philosophy

Defining artificial intelligence

https://en.wikipedia.org/wiki/Judea_Pearl
https://en.wikipedia.org/wiki/Lofti_Zadeh
https://en.wikipedia.org/wiki/Connectionism
https://en.wikipedia.org/wiki/Geoffrey_Hinton
https://en.wikipedia.org/wiki/Yann_LeCun
https://en.wikipedia.org/wiki/Convolutional_neural_networks
https://en.wikipedia.org/wiki/Narrow_AI
https://en.wikipedia.org/wiki/Statistics
https://en.wikipedia.org/wiki/Economics
https://en.wikipedia.org/wiki/Mathematical_optimization
https://en.wikipedia.org/wiki/Artificial_general_intelligence
https://en.wikipedia.org/wiki/Deep_learning
https://en.wikipedia.org/wiki/Moore%27s_law
https://en.wikipedia.org/wiki/Graphics_processing_unit
https://en.wikipedia.org/wiki/Cloud_computing
https://en.wikipedia.org/wiki/Cloud_computing
https://en.wikipedia.org/wiki/Big_data
https://en.wikipedia.org/wiki/ImageNet
https://en.wikipedia.org/wiki/Algorithmic_fairness
https://en.wikipedia.org/wiki/AI_alignment
https://en.wikipedia.org/wiki/Artificial_general_intelligence
https://en.wikipedia.org/wiki/AlphaGo
https://en.wikipedia.org/wiki/DeepMind
https://en.wikipedia.org/wiki/Go_player
https://en.wikipedia.org/wiki/GPT-3
https://en.wikipedia.org/wiki/Large_language_model
https://en.wikipedia.org/wiki/Large_language_model
https://en.wikipedia.org/wiki/OpenAI
https://en.wikipedia.org/wiki/AI_boom
https://en.wikipedia.org/wiki/Alan_Turing
https://en.wikipedia.org/wiki/Alan_Turing


4/9/24, 10:28 AM Artificial intelligence - Wikipedia

https://en.wikipedia.org/wiki/Artificial_intelligence 21/56

of a machine to simulate human conversation.[253] Since we can only observe the behavior of the
machine, it does not matter if it is "actually" thinking or literally has a "mind". Turing notes that we
can not determine these things about other people but "it is usual to have a polite convention that
everyone thinks"[284]

Russell and Norvig agree with Turing that intelligence must be defined in terms of external behavior,
not internal structure.[1] However, they are critical that the test requires the machine to imitate
humans. "Aeronautical engineering texts," they wrote, "do not define the goal of their field as making
'machines that fly so exactly like pigeons that they can fool other pigeons.' "[285] AI founder John
McCarthy agreed, writing that "Artificial intelligence is not, by definition, simulation of human
intelligence".[286]

McCarthy defines intelligence as "the computational part of the ability to achieve goals in the
world."[287] Another AI founder, Marvin Minsky similarly describes it as "the ability to solve hard
problems".[288] The leading AI textbook defines it as the study of agents that perceive their
environment and take actions that maximize their chances of achieving defined goals.[289] These
definitions view intelligence in terms of well-defined problems with well-defined solutions, where
both the difficulty of the problem and the performance of the program are direct measures of the
"intelligence" of the machine—and no other philosophical discussion is required, or may not even be
possible.

Another definition has been adopted by Google,[290] a major practitioner in the field of AI. This
definition stipulates the ability of systems to synthesize information as the manifestation of
intelligence, similar to the way it is defined in biological intelligence.

No established unifying theory or paradigm has guided AI research for most of its history.[z] The
unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so
much so that some sources, especially in the business world, use the term "artificial intelligence" to
mean "machine learning with neural networks"). This approach is mostly sub-symbolic, soft and
narrow (see below). Critics argue that these questions may have to be revisited by future generations
of AI researchers.

Symbolic AI (or "GOFAI")[292] simulated the high-level conscious reasoning that people use when
they solve puzzles, express legal reasoning and do mathematics. They were highly successful at
"intelligent" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the physical
symbol systems hypothesis: "A physical symbol system has the necessary and sufficient means of
general intelligent action."[293]

However, the symbolic approach failed on many tasks that humans solve easily, such as learning,
recognizing an object or commonsense reasoning. Moravec's paradox is the discovery that high-level
"intelligent" tasks were easy for AI, but low level "instinctive" tasks were extremely difficult.[294]

Philosopher Hubert Dreyfus had argued since the 1960s that human expertise depends on

Evaluating approaches to AI

Symbolic AI and its limits

https://en.wikipedia.org/wiki/Problem_of_other_minds
https://en.wikipedia.org/wiki/Problem_of_other_minds
https://en.wikipedia.org/wiki/Stuart_J._Russell
https://en.wikipedia.org/wiki/Peter_Norvig
https://en.wikipedia.org/wiki/Aeronautics
https://en.wikipedia.org/wiki/Pigeon
https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist)
https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist)
https://en.wikipedia.org/wiki/Marvin_Minsky
https://en.wikipedia.org/wiki/Paradigm
https://en.wikipedia.org/wiki/Sub-symbolic
https://en.wikipedia.org/wiki/Soft_computing
https://en.wikipedia.org/wiki/Artificial_general_intelligence
https://en.wikipedia.org/wiki/Symbolic_artificial_intelligence
https://en.wikipedia.org/wiki/GOFAI
https://en.wikipedia.org/wiki/Physical_symbol_systems_hypothesis
https://en.wikipedia.org/wiki/Physical_symbol_systems_hypothesis
https://en.wikipedia.org/wiki/Moravec%27s_paradox
https://en.wikipedia.org/wiki/Hubert_Dreyfus
https://en.wikipedia.org/wiki/Dreyfus%27_critique_of_AI


4/9/24, 10:28 AM Artificial intelligence - Wikipedia

https://en.wikipedia.org/wiki/Artificial_intelligence 22/56

unconscious instinct rather than conscious symbol manipulation, and on having a "feel" for the
situation, rather than explicit symbolic knowledge.[295] Although his arguments had been ridiculed
and ignored when they were first presented, eventually, AI research came to agree with him.[aa][19]

The issue is not resolved: sub-symbolic reasoning can make many of the same inscrutable mistakes
that human intuition does, such as algorithmic bias. Critics such as Noam Chomsky argue continuing
research into symbolic AI will still be necessary to attain general intelligence,[297][298] in part because
sub-symbolic AI is a move away from explainable AI: it can be difficult or impossible to understand
why a modern statistical AI program made a particular decision. The emerging field of neuro-symbolic
artificial intelligence attempts to bridge the two approaches.

"Neats" hope that intelligent behavior is described using simple, elegant principles (such as logic,
optimization, or neural networks). "Scruffies" expect that it necessarily requires solving a large
number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely
mainly on incremental testing to see if they work. This issue was actively discussed in the 1970s and
1980s,[299] but eventually was seen as irrelevant. Modern AI has elements of both.

Finding a provably correct or optimal solution is intractable for many important problems.[18] Soft
computing is a set of techniques, including genetic algorithms, fuzzy logic and neural networks, that
are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was
introduced in the late 1980s and most successful AI programs in the 21st century are examples of soft
computing with neural networks.

AI researchers are divided as to whether to pursue the goals of artificial general intelligence and
superintelligence directly or to solve as many specific problems as possible (narrow AI) in hopes these
solutions will lead indirectly to the field's long-term goals.[300][301] General intelligence is difficult to
define and difficult to measure, and modern AI has had more verifiable successes by focusing on
specific problems with specific solutions. The experimental sub-field of artificial general intelligence
studies this area exclusively.

The philosophy of mind does not know whether a machine can have a mind, consciousness and
mental states, in the same sense that human beings do. This issue considers the internal experiences
of the machine, rather than its external behavior. Mainstream AI research considers this issue
irrelevant because it does not affect the goals of the field: to build machines that can solve problems
using intelligence. Russell and Norvig add that "[t]he additional project of making a machine

Neat vs. scruffy

Soft vs. hard computing

Narrow vs. general AI

Machine consciousness, sentience and mind

https://en.wikipedia.org/wiki/Sub-symbolic
https://en.wikipedia.org/wiki/Algorithmic_bias
https://en.wikipedia.org/wiki/Noam_Chomsky
https://en.wikipedia.org/wiki/Explainable_AI
https://en.wikipedia.org/wiki/Neuro-symbolic_AI
https://en.wikipedia.org/wiki/Neuro-symbolic_AI
https://en.wikipedia.org/wiki/Logic
https://en.wikipedia.org/wiki/Optimization_(mathematics)
https://en.wikipedia.org/wiki/Artificial_neural_network
https://en.wikipedia.org/wiki/Intractability_(complexity)
https://en.wikipedia.org/wiki/Genetic_algorithms
https://en.wikipedia.org/wiki/Fuzzy_logic
https://en.wikipedia.org/wiki/Superintelligence
https://en.wikipedia.org/wiki/Philosophy_of_mind
https://en.wikipedia.org/wiki/Mind
https://en.wikipedia.org/wiki/Consciousness
https://en.wikipedia.org/wiki/Philosophy_of_mind
https://en.wikipedia.org/wiki/Stuart_J._Russell
https://en.wikipedia.org/wiki/Peter_Norvig
https://en.wikipedia.org/wiki/Philosophy_of_mind
https://en.wikipedia.org/wiki/Mind
https://en.wikipedia.org/wiki/Consciousness
https://en.wikipedia.org/wiki/Philosophy_of_mind
https://en.wikipedia.org/wiki/Stuart_J._Russell
https://en.wikipedia.org/wiki/Peter_Norvig


4/9/24, 10:28 AM Artificial intelligence - Wikipedia

https://en.wikipedia.org/wiki/Artificial_intelligence 23/56

conscious in exactly the way humans are is not one that we are equipped to take on."[302] However,
the question has become central to the philosophy of mind. It is also typically the central question at
issue in artificial intelligence in fiction.

David Chalmers identified two problems in understanding the mind, which he named the "hard" and
"easy" problems of consciousness.[303] The easy problem is understanding how the brain processes
signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it
should feel like anything at all, assuming we are right in thinking that it truly does feel like something
(Dennett's consciousness illusionism says this is an illusion). Human information processing is easy to
explain, however, human subjective experience is difficult to explain. For example, it is easy to
imagine a color-blind person who has learned to identify which objects in their field of view are red,
but it is not clear what would be required for the person to know what red looks like.[304]

Computationalism is the position in the philosophy of mind that the human mind is an information
processing system and that thinking is a form of computing. Computationalism argues that the
relationship between mind and body is similar or identical to the relationship between software and
hardware and thus may be a solution to the mind–body problem. This philosophical position was
inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally
proposed by philosophers Jerry Fodor and Hilary Putnam.[305]

Philosopher John Searle characterized this position as "strong AI": "The appropriately programmed
computer with the right inputs and outputs would thereby have a mind in exactly the same sense
human beings have minds."[ab] Searle counters this assertion with his Chinese room argument, which
attempts to show that, even if a machine perfectly simulates human behavior, there is still no reason
to suppose it also has a mind.[309]

It is di
s by computational complexity, by sample
complexity (how much data is required), or by other notions of optimization.[52]

Natural language processing (NLP)[53] allows programs to read, write and communicate in human
languages such as English. Specific problems include speech recognition, speech synthesis, machine
translation, information extraction, information retrieval and question answering.[54]

Early work, based on Noam Chomsky's generative grammar and semantic networks, had difficulty
with word-sense disambiguation[f] unless restricted to small domains called "micro-worlds" (due to
the common sense knowledge problem[32]). Margaret Masterman believed that it was meaning, and
not grammar that was the key to understanding languages, and that thesauri and not dictionaries
should be the basis of computational language structure.

Modern deep learning techniques for NLP include word embedding (representing words, typically as
vectors encoding their meaning),[55] transformers (a deep learning architecture using an attention
mechanism),[56] and others.[57] In 2019, generative pre-trained transformer (or "GPT") language
models began to generate coherent text,[58][59] and by 2023 these models were able to get human-
level scores on the bar exam, SAT test, GRE test, and many other real-world applications.[60]

Machine perception is the ability to use input from sensors (such as cameras, microphones, wireless
signals, active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Computer vision
is the ability to analyze visual input.[61]

The field includes speech recognition,[62] image classification,[63] facial recognition, object
recognition,[64] and robotic perception.[65]

Affective computing is an interdisciplinary umbrella that comprises systems that recognize, interpret,
process or simulate human feeling, emotion and mood.[67] For example, some virtual assistants are
programmed to speak conversationally or even to banter humorously; it makes them appear more

Natural language processing

Perception

Social intelligence

https://en.wikipedia.org/wiki/Unsupervised_learning
https://en.wikipedia.org/wiki/Supervised_learning
https://en.wikipedia.org/wiki/Statistical_classification
https://en.wikipedia.org/wiki/Regression_analysis
https://en.wikipedia.org/wiki/Reinforcement_learning
https://en.wikipedia.org/wiki/Transfer_learning
https://en.wikipedia.org/wiki/Deep_learning
https://en.wikipedia.org/wiki/Artificial_neural_networks
https://en.wikipedia.org/wiki/Computational_learning_theory
https://en.wikipedia.org/wiki/Computational_complexity
https://en.wikipedia.org/wiki/Sample_complexity
https://en.wikipedia.org/wiki/Sample_complexity
https://en.wikipedia.org/wiki/Optimization_theory
https://en.wikipedia.org/wiki/Natural_language_processing
https://en.wikipedia.org/wiki/English_(language)
https://en.wikipedia.org/wiki/Speech_recognition
https://en.wikipedia.org/wiki/Speech_synthesis
https://en.wikipedia.org/wiki/Machine_translation
https://en.wikipedia.org/wiki/Machine_translation
https://en.wikipedia.org/wiki/Information_extraction
https://en.wikipedia.org/wiki/Information_retrieval
https://en.wikipedia.org/wiki/Question_answering
https://en.wikipedia.org/wiki/Noam_Chomsky
https://en.wikipedia.org/wiki/Generative_grammar
https://en.wikipedia.org/wiki/Semantic_network
https://en.wikipedia.org/wiki/Word-sense_disambiguation
https://en.wikipedia.org/wiki/Blocks_world
https://en.wikipedia.org/wiki/Margaret_Masterman
https://en.wikipedia.org/wiki/Thesauri
https://en.wikipedia.org/wiki/Word_embedding
https://en.wikipedia.org/wiki/Vector_space
https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)
https://en.wikipedia.org/wiki/Attention_(machine_learning)
https://en.wikipedia.org/wiki/Generative_pre-trained_transformer
https://en.wikipedia.org/wiki/Bar_exam
https://en.wikipedia.org/wiki/Scholastic_aptitude_test
https://en.wikipedia.org/wiki/Graduate_Record_Examinations
https://en.wikipedia.org/wiki/Machine_perception
https://en.wikipedia.org/wiki/Lidar
https://en.wikipedia.org/wiki/Tactile_sensor
https://en.wikipedia.org/wiki/Computer_vision
https://en.wikipedia.org/wiki/Speech_recognition
https://en.wikipedia.org/wiki/Image_classification
https://en.wikipedia.org/wiki/Facial_recognition_system
https://en.wikipedia.org/wiki/Object_recognition
https://en.wikipedia.org/wiki/Object_recognition
https://en.wikipedia.org/wiki/Robotic_sensing
https://en.wikipedia.org/wiki/Affective_computing
https://en.wikipedia.org/wiki/Affect_(psychology)
https://en.wikipedia.org/wiki/Virtual_assistant


4/9/24, 10:28 AM Artificial intelligence - Wikipedia

https://en.wikipedia.org/wiki/Artificial_intelligence 5/56

Kismet, a robot head which was
made in the 1990s; a machine that
can recognize and simulate
emotions.[66]

sensitive to the emotional dynamics of human interaction, or to
otherwise facilitate human–computer interaction.

However, this tends to give naïve users an unrealistic conception
of the intelligence of existing computer agents.[68] Moderate
successes related to affective computing include textual sentiment
analysis and, more recently, multimodal sentiment analysis,
wherein AI classifies the affects displayed by a videotaped
subject.[69]

A machine with artificial general intelligence should be able to
solve a wide variety of problems with breadth and versatility similar to human intelligence.[14]

AI research uses a wide variety of techniques to accomplish the goals above.[b]

AI can solve many problems by intelligently searching through many possible solutions.[70] There are
two very different kinds of search used in AI: state space search and local search.

State space search searches through a tree of possible states to try to find a goal state.[71] For example,
planning algorithms search through trees of goals and subgoals, attempting to find a path to a target
goal, a process called means-ends analysis.[72]

Simple exhaustive searches[73] are rarely sufficient for most real-world problems: the search space
(the number of places to search) quickly grows to astronomical numbers. The result is a search that is
too slow or never completes.[18] "Heuristics" or "rules of thumb" can help to prioritize choices that are
more likely to reach a goal.[74]

Adversarial search is used for game-playing programs, such as chess or Go. It searches through a tree
of possible moves and counter-moves, looking for a winning position.[75]

Local search uses mathematical optimization to find a solution to a problem. It begins with some form
of guess and refines it incrementally.[76]

Gradient descent is a type of local search that optimizes a set of numerical parameters by
incrementally adjusting them to minimize a loss function. Variants of gradient descent are commonly
used to train neural networks.[77]

General intelligence

Techniques

Search and optimization

State space search

Local search

https://en.wikipedia.org/wiki/File:Kismet-IMG_6007-gradient.jpg
https://en.wikipedia.org/wiki/File:Kismet-IMG_6007-gradient.jpg
https://en.wikipedia.org/wiki/Kismet_(robot)
https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction
https://en.wikipedia.org/wiki/Sentiment_analysis
https://en.wikipedia.org/wiki/Sentiment_analysis
https://en.wikipedia.org/wiki/Multimodal_sentiment_analysis
https://en.wikipedia.org/wiki/Artificial_general_intelligence
https://en.wikipedia.org/wiki/State_space_search
https://en.wikipedia.org/wiki/Local_search_(optimization)
https://en.wikipedia.org/wiki/State_space_search
https://en.wikipedia.org/wiki/Automated_planning_and_scheduling
https://en.wikipedia.org/wiki/Means-ends_analysis
https://en.wikipedia.org/wiki/Brute_force_search
https://en.wikipedia.org/wiki/Search_algorithm
https://en.wikipedia.org/wiki/Astronomically_large
https://en.wikipedia.org/wiki/Computation_time
https://en.wikipedia.org/wiki/Heuristics
https://en.wikipedia.org/wiki/Adversarial_search
https://en.wikipedia.org/wiki/Game_AI
https://en.wikipedia.org/wiki/Game_tree
https://en.wikipedia.org/wiki/Local_search_(optimization)
https://en.wikipedia.org/wiki/Mathematical_optimization
https://en.wikipedia.org/wiki/Gradient_descent
https://en.wikipedia.org/wiki/Loss_function


4/9/24, 10:28 AM Artificial intelligence - Wikipedia

https://en.wikipedia.org/wiki/Artificial_intelligence 6/56

Illustration of gradient descent for 3
different starting points. Two
parameters (represented by the plan
coordinates) are adjusted in order to
minimize the loss function (the
height).

Another type of local search is evolutionary computation, which
aims to iteratively improve a set of candidate solutions by
"mutating" and "recombining" them, selecting only the fittest to
survive each generation.[78]

Distributed search processes can coordinate via swarm
intelligence algorithms. Two popular swarm algorithms used in
search are particle swarm optimization (inspired by bird flocking)
and ant colony optimization (inspired by ant trails).[79]

Formal logic is used for reasoning and knowledge
representation.[80] Formal logic comes in two main forms:
propositional logic (which operates on statements that are true or
false and uses logical connectives such as "and", "or", "not" and
"implies")[81] and predicate logic (which also operates on objects, predicates and relations and uses
quantifiers such as "Every X is a Y" and "There are some Xs that are Ys").[82]

Deductive reasoning in logic is the process of proving a new statement (conclusion) from other
statements that are given and assumed to be true (the premises).[83] Proofs can be structured as proof
trees, in which nodes are labelled by sentences, and children nodes are connected to parent nodes by
inference rules.

Given a problem and a set of premises, problem-solving reduces to searching for a proof tree whose
root node is labelled by a solution of the problem and whose leaf nodes are labelled by premises or
axioms. In the case of Horn clauses, problem-solving search can be performed by reasoning forwards
from the premises or backwards from the problem.[84] In the more general case of the clausal form of
first-order logic, resolution is a single, axiom-free rule of inference, in which a problem is solved by
proving a contradiction from premises that include the negation of the problem to be solved.[85]

Inference in both Horn clause logic and first-order logic is undecidable, and therefore intractable.
However, backward reasoning with Horn clauses, which underpins computation in the logic
programming language Prolog, is Turing complete. Moreover, its efficiency is competitive with
computation in other symbolic programming languages.[86]

Fuzzy logic assigns a "degree of truth" between 0 and 1. It can therefore handle propositions that are
vague and partially true.[87]

Non-monotonic logics, including logic programming with negation as failure, are designed to handle
default reasoning.[31] Other specialized versions of logic have been developed to describe many
complex domains.

Logic

Probabilistic methods for uncertain reasoning

https://en.wikipedia.org/wiki/File:Gradient_descent.gif
https://en.wikipedia.org/wiki/File:Gradient_descent.gif
https://en.wikipedia.org/wiki/Gradient_descent
https://en.wikipedia.org/wiki/Loss_function
https://en.wikipedia.org/wiki/Evolutionary_computation
https://en.wikipedia.org/wiki/Artificial_selection
https://en.wikipedia.org/wiki/Swarm_intelligence
https://en.wikipedia.org/wiki/Swarm_intelligence
https://en.wikipedia.org/wiki/Particle_swarm_optimization
https://en.wikipedia.org/wiki/Flocking_(behavior)
https://en.wikipedia.org/wiki/Ant_colony_optimization
https://en.wikipedia.org/wiki/Ant_trail
https://en.wikipedia.org/wiki/Logic
https://en.wikipedia.org/wiki/Automatic_reasoning
https://en.wikipedia.org/wiki/Knowledge_representation
https://en.wikipedia.org/wiki/Knowledge_representation
https://en.wikipedia.org/wiki/Propositional_logic
https://en.wikipedia.org/wiki/Logical_connective
https://en.wikipedia.org/wiki/Predicate_logic
https://en.wikipedia.org/wiki/Quantifier_(logic)
https://en.wikipedia.org/wiki/Deductive_reasoning
https://en.wikipedia.org/wiki/Logical_proof
https://en.wikipedia.org/wiki/Logical_consequence
https://en.wikipedia.org/wiki/Premise
https://en.wikipedia.org/wiki/Tree_structure
https://en.wikipedia.org/wiki/Inference_rule
https://en.wikipedia.org/wiki/Axiom
https://en.wikipedia.org/wiki/Horn_clause
https://en.wikipedia.org/wiki/Forward_chaining
https://en.wikipedia.org/wiki/Backward_chaining
https://en.wikipedia.org/wiki/First-order_logic
https://en.wikipedia.org/wiki/Resolution_(logic)
https://en.wikipedia.org/wiki/Undecidable_problem
https://en.wikipedia.org/wiki/Intractable_problem
https://en.wikipedia.org/wiki/Logic_programming
https://en.wikipedia.org/wiki/Logic_programming
https://en.wikipedia.org/wiki/Prolog
https://en.wikipedia.org/wiki/Turing_completeness
https://en.wikipedia.org/wiki/Symbolic_programming
https://en.wikipedia.org/wiki/Fuzzy_logic
https://en.wikipedia.org/wiki/Non-monotonic_logic
https://en.wikipedia.org/wiki/Negation_as_failure
https://en.wikipedia.org/wiki/Default_reasoning


4/9/24, 10:28 AM Artificial intelligence - Wikipedia

https://en.wikipedia.org/wiki/Artificial_intelligence 7/56

A simple Bayesian network, with the associated conditional
probability tables

Expectation-maximization clustering of Old
Faithful eruption data starts from a random
guess but then successfully converges on
an accurate clustering of the two physically
distinct modes of eruption.

Many problems in AI (including in
reasoning, planning, learning, perception,
and robotics) require the agent to operate
with incomplete or uncertain information.
AI researchers have devised a number of
tools to solve these problems using methods
from probability theory and economics.[88]

Precise mathematical tools have been
developed that analyze how an agent can
make choices and plan, using decision
theory, decision analysis,[89] and
information value theory.[90] These tools
include models such as Markov decision
processes,[91] dynamic decision
networks,[92] game theory and mechanism design.[93]

Bayesian networks[94] are a tool that can be used for reasoning (using the Bayesian inference
algorithm),[g][96] learning (using the expectation-maximization algorithm),[h][98] planning (using
decision networks)[99] and perception (using dynamic Bayesian networks).[92]

Probabilistic algorithms can also be used for filtering, prediction, smoothing and finding explanations
for streams of data, helping perception systems to analyze processes that occur over time (e.g., hidden
Markov models or Kalman filters).[92]

The simplest AI applications can be divided into two types:
classifiers (e.g., "if shiny then diamond"), on one hand, and
controllers (e.g., "if diamond then pick up"), on the other
hand. Classifiers[100] are functions that use pattern matching
to determine the closest match. They can be fine-tuned based
on chosen examples using supervised le

##Your Answer:
