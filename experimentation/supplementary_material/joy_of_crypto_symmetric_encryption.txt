You can’t learn about cryptography without meeting Alice, Bob, and Eve. This chapter is about the classic problem of private communication, in which Alice has a message that she wants to convey to Bob, while also keeping the contents of the message hidden from an eavesdropper1 Eve. You’ll soon learn that there is more to cryptography than just private communication, but it is the logical place to start.
1.1 What Is [Not] Cryptography?
“To define is to limit.”
—Oscar Wilde
Cryptography is not a magic spell that solves all security problems. Cryptography can provide solutions to cleanly defined problems that often abstract away important but messy real-world concerns. Cryptography can give guarantees about what happens in the presence of certain well-defined classes of attacks. These guarantees may not apply if real-world attackers “don’t follow the rules” of a cryptographic security model.
Always keep this in mind as we define (i.e., limit) the problems that we solve in this course.
Encryption Basics & Terminology
Let’s begin to formalize our scenario involving Alice, Bob, and Eve. Alice has a message m that she wants to send (privately) to Bob. We call m the plaintext. We assume she will somehow transform that plaintext into a value c (called the ciphertext) that she will actually send to Bob. The process of transforming m into c is called encryption, and we will useEnctorefertotheencryptionalgorithm. WhenBobreceivesc,herunsacorresponding decryption algorithm Dec to recover the original plaintext m.
We assume that the ciphertext may be observed by the eavesdropper Eve, so the (in- formal) goal is for the ciphertext to be meaningful to Bob but meaningless to Eve.
mcm
Enc Dec
1“Eavesdropper” refers to someone who secretly listens in on a conversation between others. The term originated as a reference to someone who literally hung from the eaves of a building in order to hear conver- sations happening inside.
    © Copyright Mike Rosulek. Creative Commons BY-NC-SA 4.0. Latest version at joyofcryptography.com.
Draft: January 3, 2021 CHAPTER 1. ONE-TIME PAD & KERCKHOFFS’ PRINCIPLE
 Secrets & Kerckhoffs’ Principle
Something important is missing from this picture. If we want Bob to be able to decrypt c, but Eve to not be able to decrypt c, then Bob must have some information that Eve doesn’t have (do you see why?). Something has to be kept secret from Eve.
You might suggest to make the details of the Enc and Dec algorithms secret. This is how cryptography was done throughout most of the last 2000 years, but it has major drawbacks. If the attacker does eventually learn the details of Enc and Dec, then the only way to recover security is to invent new algorithms. If you have a system with many users, then the only way to prevent everyone from reading everyone else’s messages is to invent new algorithms for each pair of users. Inventing even one good encryption method is already hard enough!
The first person to articulate this problem was Auguste Kerckhoffs. In 1883 he for- mulated a set of cryptographic design principles. Item #2 on his list is now known as Kerckhoffs’ principle:
    Kerckhoffs’ Principle:
“Il faut qu’il n’exige pas le secret, et qu’il puisse sans inconvénient tomber entre les mains de l’ennemi.”
Literal translation: [The method] must not be required to be secret, and it must be able to fall into the enemy’s hands without causing inconvenience.
Bottom line: Design your system to be secure even if the attacker has com- plete knowledge of all its algorithms.
 If the algorithms themselves are not secret, then there must be some other secret infor- mation in the system. That information is called the (secret) key. The key is just an extra piece of information given to both the Enc and Dec algorithms. Another way to interpret Kerckhoffs’ principle is that all of the security of the system should be concentrated in the secrecy of the key, not the secrecy of the algorithms. If a secret key gets compromised, you only need to choose a new one, not reinvent an entirely new encryption algorithm. Multiple users can all safely use the same encryption algorithm but with independently chosen secret keys.
The process of choosing a secret key is called key generation, and we write KeyGen to refer to the (randomized) key generation algorithm. We call the collection of three algo- rithms (Enc, Dec, KeyGen) an encryption scheme. Remember that Kerckhoffs’ principle says that we should assume that an attacker knows the details of the KeyGen algorithm. But also remember that knowing the details (i.e., source code) of a randomized algorithm doesn’t mean you know the specific output it gave when the algorithm was executed.
k mcm
 KeyGen
  Enc
Dec
   11

Draft: January 3, 2021 CHAPTER 1. ONE-TIME PAD & KERCKHOFFS’ PRINCIPLE
 Excuses, Excuses
Let’s practice some humility. Here is just a partial list of issues that are clearly important for the problem of private communication, but which are not addressed by our definition of the problem.
I We are not trying to hide the fact that Alice is sending something to Bob, we only want to hide the contents of that message. Hiding the existence of a communication channel is called steganography.
I We won’t consider the question of how c reliably gets from Alice to Bob. We’ll just take this issue for granted.
I For now, we are assuming that Eve just passively observes the communication be- tween Alice & Bob. We aren’t considering an attacker that tampers with c (causing Bob to receive and decrypt a different value), although we will consider such attacks later in the book.
I Wewon’tdiscusshowAliceandBobactuallyobtainacommonsecretkeyinthereal world. This problem (known as key distribution) is clearly incredibly important, and we will discuss some clever approaches to it much later in the book.
In my defense, the problem we are solving is already rather non-trivial: once two users have established a shared secret key, how can they use that key to communi- cate privately?
I We won’t discuss how Alice and Bob keep their key secret, even after they have established it. One of my favorite descriptions of cryptography is due to Lea Kissner (former principal security engineer at Google): “cryptography is a tool for turning lots of different problems into key management problems.”
I Throughout this course we simply assume that the users have the ability to uni- formly sample random strings. Indeed, without randomness there is no cryptogra- phy. In the real world, obtaining uniformly random bits from deterministic com- puters is extremely non-trivial. John von Neumann famously said, “Any one who considers arithmetical methods of producing random digits is, of course, in a state of sin.” Again, even when we take uniform randomness for granted, we still face the non-trivial question of how to use that randomness for private communication (and other applications), and also how to use only a manageable amount of randomness.
Not Cryptography
People use many techniques to try to hide information, but many are “non-cryptographic” since they don’t follow Kerckhoffs’ principle:
I Encoding/decodingmethodslikebase64...
joy of cryptography ↔ b25seSBuZXJkcyB3aWxsIHJlYWQgdGhpcw==
12

Draft: January 3, 2021
CHAPTER 1. ONE-TIME PAD & KERCKHOFFS’ PRINCIPLE
 I
. . . are useful for incorporating arbitrary binary data into a structured file format that supports limited kinds of characters. But since base64 encoding/decoding in- volves no secret information, it adds nothing in terms of security.
Sometimesthesimplestwaytodescribeanencryptionschemeiswithoperationson binary strings (i.e., 0s and 1s) data. As we will see, one-time pad is defined in terms of plaintexts represented as strings of bits. (Future schemes will require inputs to be represented as a bitstring of a specific length, or as an element of Zn , etc.)
In order to make sense of some algorithms in this course, it may be necessary to think about data being converted into binary representation. Just like with base64, representing things in binary has no effect on security since it does not involve any secret information. Writing something in binary is not a security measure!
1.2 Specifics of One-Time Pad
   KeyGen: Enc(k,m ∈ {0,1}λ): Dec(k,c ∈ {0,1}λ): k ← {0,1}λ returnk ⊕m returnk ⊕c return k
    Construction 1.1 (One-time pad)
People have been trying to send secret messages for roughly 2000 years, but there are really only 2 useful ideas from before 1900 that have any relevance to modern cryptography. The first idea is Kerckhoffs’ principle, which you have already seen. The other idea is one-time pad (OTP), which illustrates several important concepts, and can even still be found hiding deep inside many modern encryption schemes.
One-time pad is sometimes called “Vernam’s cipher” after Gilbert Vernam, a telegraph engineer who patented the scheme in 1919. However, an earlier description of one-time pad was rather recently discovered in an 1882 text by Frank Miller on telegraph encryp- tion.2
In most of this book, secret keys will be strings of bits. We generally use the variable λ to refer to the length (# of bits) of the secret key in a scheme, so that keys are elements of the set {0, 1}λ . In the case of one-time pad, the choice of λ doesn’t affect security (λ = 10 is “just as secure” as λ = 1000); however, the length of the keys and plaintexts must be compatible. In future chapters, increasing λ has the effect of making the scheme harder to break. For that reason, λ is often called the security parameter of the scheme.
In one-time pad, not only are the keys λ-bit strings, but plaintexts and ciphertexts are too. You should consider this to be just a simple coincidence, because we will soon encounter schemes in which keys, plaintexts, and ciphertexts are strings of different sizes.
The specific KeyGen, Enc, and Dec algorithms for one-time pad are given below:
Recall that “k ← {0, 1}λ ” means to sample k uniformly from the set of λ-bit strings. This uniform choice of key is the only randomness in all of the one-time pad algorithms. As we will see, all of its security stems from this choice of using the uniform distribution; keys that are chosen differently do not provide equivalent security.
2See the article Steven M. Bellovin: “Frank Miller: Inventor of the One-Time Pad.” Cryptologia 35 (3), 2011.
 13

Draft: January 3, 2021 CHAPTER 1. ONE-TIME PAD & KERCKHOFFS’ PRINCIPLE
 Example
Encrypting the following 20-bit plaintext m under the 20-bit key k using OTP results in the ciphertext c below:
11101111101111100011 (m) ⊕ 00011001110000111101 (k )
11110110011111011110 (c = Enc(k,m))
Decrypting the following ciphertext c using the key k results in the plaintext m below:
 Example
00001001011110010000 ⊕ 10010011101011100010 10011010110101110010
(c )
(k )
(m = Dec(k,c))
 Claim 1.2
Proof
Note that Enc and Dec are essentially the same algorithm (return the xor of the two arguments). This results in some small level of convenience and symmetry when imple- menting one-time pad, but it is more of a coincidence than something truly fundamental about encryption (see Exercises 1.12 & 2.5). Later on you’ll see encryption schemes whose encryption & decryption algorithms look very different.
Correctness
The first property of one-time pad that we should confirm is that the receiver does indeed recover the intended plaintext when decrypting the ciphertext. Without this property, the thought of using one-time pad for communication seems silly. Written mathematically:
For all k,m ∈ {0, 1}λ, it is true that Dec(k, Enc(k,m)) = m.
This follows by substituting the definitions of OTP Enc and Dec, then applying the prop-
erties of xor listed in Chapter 0.3. For all k,m ∈ {0, 1}λ, we have:
Dec(k,Enc(k,m)) = Dec(k,k ⊕m) = k ⊕ (k ⊕ m) = (k ⊕ k ) ⊕ m
=0λ ⊕m =m.
Encrypting the following plaintext m under the key k results in ciphertext c, as follows: 00110100110110001111 (m)
⊕ 11101010011010001101 11011110101100000010
Decrypting c using the same key k results in the original m:
(k ) (c )
(c )
 11011110101100000010 ⊕ 11101010011010001101
(k ) 00110100110110001111 (m)
 14

Draft: January 3, 2021 CHAPTER 1. ONE-TIME PAD & KERCKHOFFS’ PRINCIPLE
  eavesdrop(m ∈ {0,1}λ):
 k ← {0,1}λ c := k ⊕ m return c
    Example
Security
Suppose Alice and Bob are using one-time pad but are concerned that an attacker sees their ciphertext. They can’t presume what an attacker will do after seeing the ciphertext. But they would like to say something like, “because of the specific way the ciphertext was generated, it doesn’t reveal any information about the plaintext to the attacker, no matter what the attacker does with the ciphertext.”
We must first precisely specify how the ciphertext is generated. The Enc algorithm already describes the process, but it is written from the point of view of Alice and Bob. When talking about security, we have to think about what Alice and Bob do, but from the eavesdropper’s point of view! From Eve’s point of view, Alice uses a key that was chosen in a specific way (uniformly at random), she encrypts a plaintext with that key using OTP, and finally reveals only the resulting ciphertext (and not the key) to Eve.
More formally, from Eve’s perspective, seeing a ciphertext corresponds to receiving an output from the following algorithm:
.
It’s crucial that you appreciate what this eavesdrop algorithm represents. It is meant to describe not what the attacker does, but rather the process (carried out by Alice and Bob!) that produces what the attacker sees. We always treat the attacker as some (unspecified) process that receives output from this eavesdrop algorithm. Our goal is to say something like “the output of eavesdrop doesn’t reveal the input m.”
eavesdrop is a randomized algorithm — remember that “k ← {0, 1}λ ” means to sample k from the uniform distribution on λ-bit strings. If you call eavesdrop several times, even on the same input, you are likely to get different outputs. Instead of thinking of “eavesdrop(m)” as a single string, you should think of it as a probability distribution over strings. Each time you call eavesdrop(m), you see a sample from that distribution.
Let’s take λ = 3 and work out by hand the distributions eavesdrop(010) and eavesdrop(111). In each case eavesdrop chooses a value of k uniformly in {0, 1}3 — each of the possible values with probability 1/8. For each possible choice of k, we can compute what the output of eavesdrop (c) will be:
Pr k 1⁄8 000
1⁄8 001 1⁄8 010 1⁄8 011 1⁄8 100 1⁄8 101 1⁄8 110 1⁄8 111
outputc =k ⊕010 010
      011
      000
      001
      110
      111
      100
      101
Pr k 1⁄8 000
1⁄8 001 1⁄8 010 1⁄8 011 1⁄8 100 1⁄8 101 1⁄8 110 1⁄8 111
outputc =k ⊕111 111
      110
      101
      100
      011
      010
      001
      000
eavesdrop(010):
eavesdrop(111):
    15

 Claim 1.3
Proof
So the distribution eavesdrop(010) assigns probabilty 1/8 to 010, probability 1/8 to 011, and so on.
In this example, notice how every string in {0, 1}3 appears exactly once in the c column of eavesdrop(010). This means that eavesdrop assigns probability 1/8 to every string in {0, 1}3, which is just another way of saying that the distribution is the uniform distribu- tion on {0, 1}3. The same can be said about the distribution eavesdrop(111), too. Both distributions are just the uniform distribution in disguise!
There is nothing special about 010 or 111 in these examples. For any λ and any m ∈ {0, 1}λ , the distribution eavesdrop(m) is the uniform distribution over {0, 1}λ .
For every m ∈ {0,1}λ, the distribution eavesdrop(m) is the uniform distribution on {0,1}λ. Hence,forallm,m′ ∈ {0,1}λ,thedistributionseavesdrop(m)andeavesdrop(m′) are identical.
Arbitrarily fix m, c ∈ {0, 1}λ . We will calculate the probability that eavesdrop(m) pro- duces output c. That event happens only when
c = k ⊕ m ⇐⇒ k = m ⊕ c .
The equivalence follows from the properties of xor given in Section 0.3. That is,
Pr[eavesdrop(m) = c] = Pr[k = m ⊕ c],
where the probability is over uniform choice of k ← {0, 1}λ .
We are considering a specific choice for m and c, so there is only one value of k that
makes k = m ⊕ c true (causes m to encrypt to c), and that value is exactly m ⊕ c. Since k is chosen uniformly from {0, 1}λ , the probability of choosing the particular value k = m ⊕ c is 1/2λ .
In summary, for every m and c, the probability that eavesdrop(m) outputs c is ex- actly 1/2λ . This means that the output of eavesdrop(m), for any m, follows the uniform distribution. 
One way to interpret this statement of security in more down-to-earth terms:
If an attacker sees a single ciphertext, encrypted with one-time pad, where the key is chosen uniformly and kept secret from the attacker, then the ciphertext appears uniformly distributed.
Why is this significant? Taking the eavesdropper’s point of view, suppose someone chooses a plaintext m and you get to see the resulting ciphertext — a sample from the distri- bution eavesdrop(m). But this is a distribution that you can sample from yourself, even if you don’t know m! You could have chosen a totally different m′ and run eavesdrop(m′) in your imagination, and this would have produced the same distribution as eavesdrop(m). The “real” ciphertext that you see doesn’t carry any information about m if it is possible to sample from the same distribution without even knowing m!
16

 Discussion
I Isn’t there a paradox? Claim 1.2 says that c can always be decrypted to get m, but Claim 1.3 says that c contains no information about m! The answer to this riddle is that Claim 1.2 talks about what can be done with knowledge of the key k (Alice & Bob’s perspective). Claim 1.3 talks about the output distribution of the eavesdrop algorithm, which doesn’t include k (Eve’s perspective). In short, if you know k, then you can decrypt c to obtain m; if you don’t know k, then c carries no information about m (in fact, it looks uniformly distributed). This is because m, c, k are all correlated in a delicate way.3
I Isn’t there another paradox? Claim 1.3 says that the output of eavesdrop(m) doesn’t depend on m, but we can see the eavesdrop algorithm literally using its argument m right there in the last line! The answer to this riddle is perhaps best illustrated by the previous illustrations of the eavesdrop(010) and eavesdrop(111) distributions. The two tables of values are indeed different (so the choice of m ∈ {010, 111} clearly has some effect), but they represent the same probability distribu- tion (since order doesn’t matter). Claim 1.3 considers only the resulting probability distribution.
I You probably think about security in terms of a concrete “goal” for the attacker: recover the key, recover the plaintext, etc. Claim 1.3 doesn’t really refer to attackers in that way, and it certainly doesn’t specify a goal. Rather, we are thinking about security by comparing to some hypothetical “ideal” world. I would be satisfied if the attacker sees only a source of uniform bits, because in this hypothetical world there are no keys and no plaintexts to recover! Claim 1.3 says that when we actually use OTP, it looks just like this hypothetical world, from the attacker’s point of view. If we imagine any “goal” at all for the attacker in this kind of reasoning, it’s to detect that ciphertexts don’t follow a uniform distribution. By showing that the attacker can’t even achieve this modest goal, it shows that the attacker couldn’t possibly achieve other, more natural, goals like key recovery and plaintext recovery.
Limitations
One-time pad is incredibly limited in practice. Most notably:
I Itskeysareaslongastheplaintextstheyencrypt.Thisisbasicallyunavoidable(see Exercise 2.11) and leads to a kind of chicken-and-egg dilemma in practice: If two users want to privately convey a λ-bit message, they first need to privately agree on a λ-bit string.
I A key can be used to encrypt only one plaintext (hence, “one-time” pad); see Exer- cise 1.6. Indeed, we can see that the eavesdrop subroutine in Claim 1.3 provides no way for a caller to guarantee that two plaintexts are encrypted with the same key, so it is not clear how to use Claim 1.3 to argue about what happens in one-time pad when keys are intentionally reused in this way.
 
Despite these limitations, one-time pad illustrates fundamental ideas that appear in most forms of encryption in this course.





Edgar Allan Poe was not only an author, but also a cryptography enthusiast. He once wrote, in a discussion on the state of the art in cryptography:1
“Human ingenuity cannot concoct a cipher which human ingenuity cannot resolve.”
This was an accurate assessment of the cryptography that existed in 1841. Whenever someone would come up with an encryption method, someone else would inevitably find a way to break it, and the cat-and-mouse game would repeat again and again.
Modern 21st-century cryptography, however, is different. This book will introduce you to many schemes whose security we can prove in a very specific sense. The code- makers can win against the code-breakers.
It’s only possible to prove things about security by having formal definitions of what it means to be “secure.” This chapter is about the fundamental skills that revolve around security definitions: how to write them, how to understand & interpret them, how to prove security using the hybrid technique, and how to demonstrate insecurity using attacks against the security definition.
2.1 How to Write a Security Definition
So far the only form of cryptography we’ve seen is one-time pad, so our discussion of secu- rity has been rather specific to one-time pad. It would be preferable to have a vocabulary to talk about security in a more general sense, so that we can ask whether any encryption scheme is secure.
In this section, we’ll develop two security definitions for encryption.
What Doesn’t Go Into a Security Definition
A security definition should give guarantees about what can happen to a system in the presence of an attacker. But not all important properties of a system refer to an attacker. For encryption specifically:
I We don’t reference any attacker when we say that the Enc algorithm takes two arguments (a key and a plaintext), or that the KeyGen algorithm takes no arguments. Specifying the types of inputs/outputs (i.e., the “function signature”) of the various algorithms is therefore not a statement about security. We call these properties the syntax of the scheme.
1Edgar Allan Poe, “A Few Words on Secret Writing,” Graham’s Magazine, July 1841, v19.
 © Copyright Mike Rosulek. Creative Commons BY-NC-SA 4.0. Latest version at joyofcryptography.com.
Draft: January 3, 2021 CHAPTER 2. THE BASICS OF PROVABLE SECURITY
 Definition 2.1 (Encryption syntax)
I Even if there is no attacker, it’s still important that decryption is an inverse of en- cryption. This is not a security property of the encryption scheme. Instead, we call it a correctness property.
Below are the generic definitions for syntax and correctness of symmetric-key encryp- tion:
A symmetric-key encryption (SKE) scheme consists of the following algorithms:
I KeyGen: a randomized algorithm that outputs a key k ∈ K.
I Enc: a (possibly randomized) algorithm that takes a key k ∈ K and plaintext m ∈ M as input, and outputs a ciphertext c ∈ C.
I Dec: a deterministic algorithm that takes a key k ∈ K and ciphertext c ∈ C as input, and outputs a plaintext m ∈ M.
We call K the key space, M the message space, and C the ciphertext space of the scheme. Sometimes we refer to the entire scheme (the collection of all three algorithms) by a single variable Σ. When we do so, we write Σ.KeyGen, Σ.Enc, Σ.Dec, Σ.K, Σ.M, and Σ.C to refer to its components.
An encryption scheme Σ satisfies correctness if for all k ∈ Σ.K and all m ∈ Σ.M, hi
Pr Σ.Dec(k,Σ.Enc(k,m))=m =1.
The definition is written in terms of a probability because Enc is allowed to be a random- ized algorithm. In other words, decrypting a ciphertext with the same key that was used for encryption must always result in the original plaintext.
An encryption scheme can have the appropriate syntax but still have degenerate behavior like Enc(k,m) = 0λ (i.e., every plaintext is “encrypted” to 0λ). Such a scheme would not satisfy the correctness property.
A different scheme defined by Enc(k,m) = m (i.e., the “ciphertext” is always equal to the plaintext itself) and Dec(k,c) = c does satisfy the correctness property, but would not satisfy any reasonable security property.
“Real-vs-Random” Style of Security Definition
Let’s try to make a security definition that formalizes the following intuitive idea:
“an encryption scheme is a good one if its ciphertexts look like random junk to an attacker.”
Security definitions always consider the attacker’s view of the system. What is the “in- terface” that Alice & Bob expose to the attacker by their use of the cryptography, and does that particular interface benefit the attacker?
In this example, we’re considering a scenario where the attacker gets to observe ci- phertexts. How exactly are these ciphertexts generated? What are the inputs to Enc (key and plaintext), and how are they chosen?
Definition 2.2 (SKE correctness)
Example
22

Draft: January 3, 2021 CHAPTER 2. THE BASICS OF PROVABLE SECURITY
 I Key: It’s hard to imagine any kind of useful security if the attacker knows the key. Hence, we consider that the key is kept secret from the attacker. Of course, the key is generated according to the KeyGen algorithm of the scheme.
At this point in the course, we consider encryption schemes where the key is used to encrypt only one plaintext. Somehow this restriction must be captured in our security definition. Later, we will consider security definitions that consider a key that is used to encrypt many things.
I Plaintext:Itturnsouttobeusefultoconsiderthattheattackeractuallychoosesthe plaintexts. This a “pessimistic” choice, since it gives much power to the attacker. However, if the encryption scheme is indeed secure when the attacker chooses the plaintexts, then it’s also secure in more realistic scenarios where the attacker has some uncertainty about the plaintexts.
These clarifications allow us to fill in more specifics about our informal idea of security:
“an encryption scheme is a good one if its ciphertexts look like random junk to an attacker . . . when each key is secret and used to encrypt only one plaintext, even when the attacker chooses the plaintexts.”
A concise way to express all of these details is to consider the attacker as a calling program to the following subroutine:
.
A calling program can choose the argument to the subroutine (in this case, a plaintext), and see only the resulting return value (in this case, a ciphertext). The calling program can’t see values of privately-scoped variables (like k in this case). If the calling program makes many calls to the subroutine, a fresh key k is chosen each time.
The interaction between an attacker (calling program) and this ctxt subroutine ap- pears to capture the relevant scenario. We would like to say that the outputs from the ctxt subroutine are uniformly distributed. A convenient way of expressing this property is to say that this ctxt subroutine should have the same effect on every calling program as a ctxt subroutine that (explicitly) samples its output uniformly.
vs. .
Intuitively, no calling program should have any way of determining which of these two implementations is answering subroutine calls. As an analogy, one way of saying that “foo is a correct sorting algorithm” is to say that “no calling program would behave differently if foo were replaced by an implementation of mergesort.”
In summary, we can define security for encryption in the following way: 23
  ctxt(m ∈ Σ.M): k ← Σ.KeyGen
c := Σ.Enc(k,m) return c
  ctxt(m ∈ Σ.M): k ← Σ.KeyGen
c := Σ.Enc(k,m) return c
 ctxt(m ∈ Σ.M):
 c ← Σ.C return c
    
Draft: January 3, 2021 CHAPTER 2. THE BASICS OF PROVABLE SECURITY
 Example
“an encryption scheme is a good one if, when you plug its KeyGen and Enc algo- rithms into the template of the ctxt subroutine above, the two implementations of ctxt induce identical behavior in every calling program.”
In a few pages, we introduce formal notation and definitions for the concepts introduced here. In particular, both the calling program and subroutine can be randomized algorithms, so we should be careful about what we mean by “identical behavior.”
One-time pad is defined with KeyGen sampling k uniformly from {0, 1}λ and Enc(k,m) = k ⊕ m. It satisfies our new security property since, when we plug in this algorithms into the above template, we get the following two subroutine implementations:
vs. ,
and these two implementations have the same effect on all calling programs.
“Left-vs-Right” Style of Security Definition
Here’s a different intuitive idea of security:
“an encryption scheme is a good one if encryptions of mL look like encryptions ofmR toanattacker(forallpossiblemL,mR)”
As above, we are considering a scenario where the attacker sees some ciphertext(s). These ciphertexts are generated with some key; where does that key come from? These ciphertexts encrypt either some mL or some mR ; where do mL and mR come from? We can answer these questions in a similar way as the previous example. Plaintexts mL and mR can be chosen by the attacker. The key is chosen according to KeyGen so that it remains secret from the attacker (and is used to generate only one ciphertext).
“an encryption scheme is a good one if encryptions of mL look like encryptions of mR to an attacker, when each key is secret and used to encrypt only one plaintext, even when the attacker chooses mL and mR .”
As before, we formalize this idea by imagining the attacker as a program that calls a par- ticular interface. This time, the attacker will choose two plaintexts mL and mR , and get a ciphertext in return.2 Depending on whether mL or mR is actually encrypted, those interfaces are implemented as follows:
;.
2There may be other reasonable ways to formalize this intuitive idea of security. For example, we might choose to give the attacker two ciphertexts instead of one, and demand that the attacker can’t determine which of them encrypts mL and which encrypts mR . See Exercise 2.15.
  ctxt(m):
k ← {0, 1}λ // KeyGen of OTP
c :=k ⊕m //EncofOTP return c
  ctxt(m):
c←{0,1}λ //CofOTP return c
 eavesdrop(mL,mR ∈ Σ.M):
 k ← Σ.KeyGen
c := Σ.Enc(k,mL) return c
    eavesdrop(mL,mR ∈ Σ.M):
 k ← Σ.KeyGen
c := Σ.Enc(k,mR) return c
      24

Draft: January 3, 2021 CHAPTER 2. THE BASICS OF PROVABLE SECURITY
 Example
Now the formal way to say that encryptions of mL “look like” encryptions of mR is:
“an encryption scheme is a good one if, when you plug its KeyGen and Enc algorithms into the template of the eavesdrop subroutines above, the two imple- mentations of eavesdrop induce identical behavior in every calling program.”
Does one-time pad satisfy this new security property? To find out, we plug in its algorithms to the above template, and obtain the following implementations:
If these two implementations have the same effect on all calling programs (and indeed they do), then we would say that OTP satisfies this security property.
Is this a better/worse way to define security than the previous way? One security definition considers an attacker whose goal is to distinguish real ciphertexts from ran- dom values (real-vs-random paradigm), and the other considers an attacker whose goal is to distinguish real ciphertexts of two different plaintexts (left-vs-right paradigm). Is one “correct” and the other one “incorrect?” We save such discussion until later in the chapter.
Formalisms for Security Definitions
So far, we’ve defined security in terms of a single, self-contained subroutine, and imagined the attacker as a program that calls this subroutine. Later in the course we will need to generalize beyond a single subroutine, to a collection of subroutines that share common (private) state information. Staying with the software terminology, we call this collection a library:
A library L is a collection of subroutines and private/static variables. A library’s interface consists of the names, argument types, and output type of all of its subroutines (just like a Java interface). If a program A includes calls to subroutines in the interface of L, then we write A ⋄ L to denote the result of linking A to L in the natural way (answering those subroutine calls using the implementation specified in L). We write A ⋄ L ⇒ z to denote the event that program A ⋄ L outputs the value z.
If A or L is a program that makes random choices, then the output of A ⋄ L is a random variable. It is often useful to consider probabilities like Pr[A ⋄ L ⇒ true].
Here is a familiar library:
    2.2
Definition 2.3 (Libraries)
Example
eavesdrop(mL,mR):
k ← {0, 1}λ // KeyGen of OTP
c:=k⊕mL //EncofOTP return c
eavesdrop(mL,mR):
k ← {0, 1}λ // KeyGen of OTP
c:=k⊕mR //EncofOTP return c
   L
 ctxt(m):
k ← {0,1}λ
c := k ⊕ m return c
   25

Draft: January 3, 2021 CHAPTER 2. THE BASICS OF PROVABLE SECURITY
 
A:
m ← {0,1}λ c := ctxt(m)
returnm=? c
Example
And here is one possible calling program:
You can hopefully convince yourself that
Pr[A ⋄ L ⇒ true] = 1/2λ .
If this A is linked to a different library, its output probability may be different. If a different
calling program is linked to this L, the output probability may be different.
A library can contain several subroutines and private variables that are kept static between subroutine calls. For example, here is a simple library that picks a string s uniformly and allows the calling program to guess s.
L
s ← {0,1}λ reset():
s ← {0,1}λ guess(x ∈ {0,1}λ):
 
return x =? s
Definition 2.4 (Interchangeable)
Let L and L be two libraries that have the same interface. We say that L and L
left
right
Our convention is that code outside of a subroutine (like the first line here) is run once at initialization time. Variables defined at initialization time (like s here) are available in all subroutine scopes (but not to the calling program).
Interchangeability
The idea that “no calling program behaves differently in the presence of these two li- braries” still makes sense even for libraries with several subroutines. Since this is such a common concept, we devote new notation to it:
left right
are interchangeable, and write L value,
, if for all programs A that output a boolean Pr[A ⋄ Lleft ⇒ true] = Pr[A ⋄ Lright ⇒ true].
left
≡ L
right
This definition considers calling programs that give boolean output. Imagine a calling program / attacker whose only goal is to distinguish two particular libraries (indeed, we often refer to the calling program as a distinguisher). A boolean output is enough for that task. You can think of the output bit as the calling program’s “guess” for which library the calling program thinks it is linked to.



Edgar Allan Poe was not only an author, but also a cryptography enthusiast. He once wrote, in a discussion on the state of the art in cryptography:1
“Human ingenuity cannot concoct a cipher which human ingenuity cannot resolve.”
This was an accurate assessment of the cryptography that existed in 1841. Whenever someone would come up with an encryption method, someone else would inevitably find a way to break it, and the cat-and-mouse game would repeat again and again.
Modern 21st-century cryptography, however, is different. This book will introduce you to many schemes whose security we can prove in a very specific sense. The code- makers can win against the code-breakers.
It’s only possible to prove things about security by having formal definitions of what it means to be “secure.” This chapter is about the fundamental skills that revolve around security definitions: how to write them, how to understand & interpret them, how to prove security using the hybrid technique, and how to demonstrate insecurity using attacks against the security definition.
2.1 How to Write a Security Definition
So far the only form of cryptography we’ve seen is one-time pad, so our discussion of secu- rity has been rather specific to one-time pad. It would be preferable to have a vocabulary to talk about security in a more general sense, so that we can ask whether any encryption scheme is secure.
In this section, we’ll develop two security definitions for encryption.
What Doesn’t Go Into a Security Definition
A security definition should give guarantees about what can happen to a system in the presence of an attacker. But not all important properties of a system refer to an attacker. For encryption specifically:
I We don’t reference any attacker when we say that the Enc algorithm takes two arguments (a key and a plaintext), or that the KeyGen algorithm takes no arguments. Specifying the types of inputs/outputs (i.e., the “function signature”) of the various algorithms is therefore not a statement about security. We call these properties the syntax of the scheme.
1Edgar Allan Poe, “A Few Words on Secret Writing,” Graham’s Magazine, July 1841, v19.
 © Copyright Mike Rosulek. Creative Commons BY-NC-SA 4.0. Latest version at joyofcryptography.com.
Draft: January 3, 2021 CHAPTER 2. THE BASICS OF PROVABLE SECURITY
 Definition 2.1 (Encryption syntax)
I Even if there is no attacker, it’s still important that decryption is an inverse of en- cryption. This is not a security property of the encryption scheme. Instead, we call it a correctness property.
Below are the generic definitions for syntax and correctness of symmetric-key encryp- tion:
A symmetric-key encryption (SKE) scheme consists of the following algorithms:
I KeyGen: a randomized algorithm that outputs a key k ∈ K.
I Enc: a (possibly randomized) algorithm that takes a key k ∈ K and plaintext m ∈ M as input, and outputs a ciphertext c ∈ C.
I Dec: a deterministic algorithm that takes a key k ∈ K and ciphertext c ∈ C as input, and outputs a plaintext m ∈ M.
We call K the key space, M the message space, and C the ciphertext space of the scheme. Sometimes we refer to the entire scheme (the collection of all three algorithms) by a single variable Σ. When we do so, we write Σ.KeyGen, Σ.Enc, Σ.Dec, Σ.K, Σ.M, and Σ.C to refer to its components.
An encryption scheme Σ satisfies correctness if for all k ∈ Σ.K and all m ∈ Σ.M, hi
Pr Σ.Dec(k,Σ.Enc(k,m))=m =1.
The definition is written in terms of a probability because Enc is allowed to be a random- ized algorithm. In other words, decrypting a ciphertext with the same key that was used for encryption must always result in the original plaintext.
An encryption scheme can have the appropriate syntax but still have degenerate behavior like Enc(k,m) = 0λ (i.e., every plaintext is “encrypted” to 0λ). Such a scheme would not satisfy the correctness property.
A different scheme defined by Enc(k,m) = m (i.e., the “ciphertext” is always equal to the plaintext itself) and Dec(k,c) = c does satisfy the correctness property, but would not satisfy any reasonable security property.
“Real-vs-Random” Style of Security Definition
Let’s try to make a security definition that formalizes the following intuitive idea:
“an encryption scheme is a good one if its ciphertexts look like random junk to an attacker.”
Security definitions always consider the attacker’s view of the system. What is the “in- terface” that Alice & Bob expose to the attacker by their use of the cryptography, and does that particular interface benefit the attacker?
In this example, we’re considering a scenario where the attacker gets to observe ci- phertexts. How exactly are these ciphertexts generated? What are the inputs to Enc (key and plaintext), and how are they chosen?
Definition 2.2 (SKE correctness)
Example
22

Draft: January 3, 2021 CHAPTER 2. THE BASICS OF PROVABLE SECURITY
 I Key: It’s hard to imagine any kind of useful security if the attacker knows the key. Hence, we consider that the key is kept secret from the attacker. Of course, the key is generated according to the KeyGen algorithm of the scheme.
At this point in the course, we consider encryption schemes where the key is used to encrypt only one plaintext. Somehow this restriction must be captured in our security definition. Later, we will consider security definitions that consider a key that is used to encrypt many things.
I Plaintext:Itturnsouttobeusefultoconsiderthattheattackeractuallychoosesthe plaintexts. This a “pessimistic” choice, since it gives much power to the attacker. However, if the encryption scheme is indeed secure when the attacker chooses the plaintexts, then it’s also secure in more realistic scenarios where the attacker has some uncertainty about the plaintexts.
These clarifications allow us to fill in more specifics about our informal idea of security:
“an encryption scheme is a good one if its ciphertexts look like random junk to an attacker . . . when each key is secret and used to encrypt only one plaintext, even when the attacker chooses the plaintexts.”
A concise way to express all of these details is to consider the attacker as a calling program to the following subroutine:
.
A calling program can choose the argument to the subroutine (in this case, a plaintext), and see only the resulting return value (in this case, a ciphertext). The calling program can’t see values of privately-scoped variables (like k in this case). If the calling program makes many calls to the subroutine, a fresh key k is chosen each time.
The interaction between an attacker (calling program) and this ctxt subroutine ap- pears to capture the relevant scenario. We would like to say that the outputs from the ctxt subroutine are uniformly distributed. A convenient way of expressing this property is to say that this ctxt subroutine should have the same effect on every calling program as a ctxt subroutine that (explicitly) samples its output uniformly.
vs. .
Intuitively, no calling program should have any way of determining which of these two implementations is answering subroutine calls. As an analogy, one way of saying that “foo is a correct sorting algorithm” is to say that “no calling program would behave differently if foo were replaced by an implementation of mergesort.”
In summary, we can define security for encryption in the following way: 23
  ctxt(m ∈ Σ.M): k ← Σ.KeyGen
c := Σ.Enc(k,m) return c
  ctxt(m ∈ Σ.M): k ← Σ.KeyGen
c := Σ.Enc(k,m) return c
 ctxt(m ∈ Σ.M):
 c ← Σ.C return c
    
Draft: January 3, 2021 CHAPTER 2. THE BASICS OF PROVABLE SECURITY
 Example
“an encryption scheme is a good one if, when you plug its KeyGen and Enc algo- rithms into the template of the ctxt subroutine above, the two implementations of ctxt induce identical behavior in every calling program.”
In a few pages, we introduce formal notation and definitions for the concepts introduced here. In particular, both the calling program and subroutine can be randomized algorithms, so we should be careful about what we mean by “identical behavior.”
One-time pad is defined with KeyGen sampling k uniformly from {0, 1}λ and Enc(k,m) = k ⊕ m. It satisfies our new security property since, when we plug in this algorithms into the above template, we get the following two subroutine implementations:
vs. ,
and these two implementations have the same effect on all calling programs.
“Left-vs-Right” Style of Security Definition
Here’s a different intuitive idea of security:
“an encryption scheme is a good one if encryptions of mL look like encryptions ofmR toanattacker(forallpossiblemL,mR)”
As above, we are considering a scenario where the attacker sees some ciphertext(s). These ciphertexts are generated with some key; where does that key come from? These ciphertexts encrypt either some mL or some mR ; where do mL and mR come from? We can answer these questions in a similar way as the previous example. Plaintexts mL and mR can be chosen by the attacker. The key is chosen according to KeyGen so that it remains secret from the attacker (and is used to generate only one ciphertext).
“an encryption scheme is a good one if encryptions of mL look like encryptions of mR to an attacker, when each key is secret and used to encrypt only one plaintext, even when the attacker chooses mL and mR .”
As before, we formalize this idea by imagining the attacker as a program that calls a par- ticular interface. This time, the attacker will choose two plaintexts mL and mR , and get a ciphertext in return.2 Depending on whether mL or mR is actually encrypted, those interfaces are implemented as follows:
;.
2There may be other reasonable ways to formalize this intuitive idea of security. For example, we might choose to give the attacker two ciphertexts instead of one, and demand that the attacker can’t determine which of them encrypts mL and which encrypts mR . See Exercise 2.15.
  ctxt(m):
k ← {0, 1}λ // KeyGen of OTP
c :=k ⊕m //EncofOTP return c
  ctxt(m):
c←{0,1}λ //CofOTP return c
 eavesdrop(mL,mR ∈ Σ.M):
 k ← Σ.KeyGen
c := Σ.Enc(k,mL) return c
    eavesdrop(mL,mR ∈ Σ.M):
 k ← Σ.KeyGen
c := Σ.Enc(k,mR) return c
      24

Draft: January 3, 2021 CHAPTER 2. THE BASICS OF PROVABLE SECURITY
 Example
Now the formal way to say that encryptions of mL “look like” encryptions of mR is:
“an encryption scheme is a good one if, when you plug its KeyGen and Enc algorithms into the template of the eavesdrop subroutines above, the two imple- mentations of eavesdrop induce identical behavior in every calling program.”
Does one-time pad satisfy this new security property? To find out, we plug in its algorithms to the above template, and obtain the following implementations:
If these two implementations have the same effect on all calling programs (and indeed they do), then we would say that OTP satisfies this security property.
Is this a better/worse way to define security than the previous way? One security definition considers an attacker whose goal is to distinguish real ciphertexts from ran- dom values (real-vs-random paradigm), and the other considers an attacker whose goal is to distinguish real ciphertexts of two different plaintexts (left-vs-right paradigm). Is one “correct” and the other one “incorrect?” We save such discussion until later in the chapter.
Formalisms for Security Definitions
So far, we’ve defined security in terms of a single, self-contained subroutine, and imagined the attacker as a program that calls this subroutine. Later in the course we will need to generalize beyond a single subroutine, to a collection of subroutines that share common (private) state information. Staying with the software terminology, we call this collection a library:
A library L is a collection of subroutines and private/static variables. A library’s interface consists of the names, argument types, and output type of all of its subroutines (just like a Java interface). If a program A includes calls to subroutines in the interface of L, then we write A ⋄ L to denote the result of linking A to L in the natural way (answering those subroutine calls using the implementation specified in L). We write A ⋄ L ⇒ z to denote the event that program A ⋄ L outputs the value z.
If A or L is a program that makes random choices, then the output of A ⋄ L is a random variable. It is often useful to consider probabilities like Pr[A ⋄ L ⇒ true].
Here is a familiar library:
    2.2
Definition 2.3 (Libraries)
Example
eavesdrop(mL,mR):
k ← {0, 1}λ // KeyGen of OTP
c:=k⊕mL //EncofOTP return c
eavesdrop(mL,mR):
k ← {0, 1}λ // KeyGen of OTP
c:=k⊕mR //EncofOTP return c
   L
 ctxt(m):
k ← {0,1}λ
c := k ⊕ m return c
   25

Draft: January 3, 2021 CHAPTER 2. THE BASICS OF PROVABLE SECURITY
 
A:
m ← {0,1}λ c := ctxt(m)
returnm=? c
Example
And here is one possible calling program:
You can hopefully convince yourself that
Pr[A ⋄ L ⇒ true] = 1/2λ .
If this A is linked to a different library, its output probability may be different. If a different
calling program is linked to this L, the output probability may be different.
A library can contain several subroutines and private variables that are kept static between subroutine calls. For example, here is a simple library that picks a string s uniformly and allows the calling program to guess s.
L
s ← {0,1}λ reset():
s ← {0,1}λ guess(x ∈ {0,1}λ):
 
return x =? s
Definition 2.4 (Interchangeable)
Let L and L be two libraries that have the same interface. We say that L and L
left
right
Our convention is that code outside of a subroutine (like the first line here) is run once at initialization time. Variables defined at initialization time (like s here) are available in all subroutine scopes (but not to the calling program).
Interchangeability
The idea that “no calling program behaves differently in the presence of these two li- braries” still makes sense even for libraries with several subroutines. Since this is such a common concept, we devote new notation to it:
left right
are interchangeable, and write L value,
, if for all programs A that output a boolean Pr[A ⋄ Lleft ⇒ true] = Pr[A ⋄ Lright ⇒ true].
left
≡ L
right
This definition considers calling programs that give boolean output. Imagine a calling program / attacker whose only goal is to distinguish two particular libraries (indeed, we often refer to the calling program as a distinguisher). A boolean output is enough for that task. You can think of the output bit as the calling program’s “guess” for which library the calling program thinks it is linked to.


DNS is the system that maps human-memorable Internet domains like irs.gov to machine-readable IP addresses like 166.123.218.220. If an attacker can masquerade as the DNS system and convince your computer that irs.gov actually resides at some other IP address, it might result in a bad day for you.
To protect against these kinds of attacks, a replacement called DNSSEC has been pro- posed. DNSSEC uses cryptography to make it impossible to falsify a domain-name map- ping. The cryptography required to authenticate DNS mappings is certainly interesting, but an even more fundamental question remains: Who can be trusted with the master cryp- tographic keys to the system? The non-profit organization in charge of these kinds of things (ICANN) has chosen the following system. The master key is split into 7 pieces and dis- tributed on smart cards to 7 geographically diverse people, who keep them in safe-deposit boxes.
At least five key-holding members of this fellowship would have to meet at a secure data center in the United States to reboot [DNSSEC] in case of a very unlikely system collapse.
“If you round up five of these guys, they can decrypt [the root key] should the West Coast fall in the water and the East Coast get hit by a nuclear bomb," [said] Richard Lamb, program manager for DNSSEC at ICANN.1
How is it possible that any 5 out of the 7 key-holders can reconstruct the master key, but (presumably) 4 out of the 7 cannot? The solution lies in a cryptographic tool called a secret-sharing scheme, the topic of this chapter.
3.1 Definitions
 © Copyright Mike Rosulek. Creative Commons BY-NC-SA 4.0. Latest version at joyofcryptography.com.
Draft: January 3, 2021 CHAPTER 3. SECRET SHARING
 Definition 3.2 (TSSS correctness)
In secret-sharing, we number the users as {1, . . . , n}, with user i receiving share si . Let U ⊆{1,...,n}beasubsetofusers.Then{si |i∈U}referstothesetofsharesbelonging to users U . If |U | > t , we say that U is authorized; otherwise it is unauthorized. The goal of secret sharing is for all authorized sets of users/shares to be able to reconstruct the secret, while all unauthorized sets learn nothing.
At-out-of-nTSSSsatisfiescorrectnessif,forallauthorizedsetsU ⊆ {1,...,n}(i.e.,|U| >t) andforalls←Share(m),wehaveReconstruct({si |i∈U})=m.
m
s1 s2 s3 s4 s5 · · · sn n shares any t of the shares
m
Security Definition
We’d like a security guarantee that says something like:
if you know only an unauthorized set of shares, then you learn no information about the choice of secret message.
To translate this informal statement into a formal security definition, we define two li- braries that allow the calling program to learn a set of shares (for an unauthorized set), and that differ only in which secret is shared. If the two libraries are interchangeable, then we conclude that seeing an unauthorized set of shares leaks no information about the choice of secret message. The definition looks like this:
Let Σ be a threshold secret-sharing scheme. We say that Σ is secure if LΣ ≡ LΣ , where: tsss-L tsss-R
In an attempt to keep the notation uncluttered, we have not written the type of the argument U,whichisU ⊆ {1,...,Σ.n}.
 Share
    Definition 3.3 (TSSS security)
Reconstruct
     LΣ tsss-L
share(mL,mR ∈ Σ.M,U):
 if |U | > Σ.t: return err s ← Σ.Share(mL) return{si |i∈U}
  LΣ tsss-R
share(mL,mR ∈ Σ.M,U):
 if |U | > Σ.t: return err s ← Σ.Share(mR) return{si |i∈U}
   48

Draft: January 3, 2021 CHAPTER 3. SECRET SHARING
 Discussion & Pitfalls
I Similar to the definition of one-time secrecy of encryption, we let the calling pro- gram choose the two secret messages that will be shared. As before, this models an attack scenario in which the adversary has partial knowledge or influence on the secret m being shared.
I The calling program also chooses the set U of users’ shares to obtain. The libraries make it impossible for the calling program to obtain the shares of an authorized set (returning err in that case). This does not mean that a user is never allowed to dis- tribute an authorized number of shares (this would be strange indeed, since it would make any future reconstruction impossible). It just means that we want a security definition that says something about an attacker who sees only an unauthorized set of shares, so we formalize security in terms of libraries with this restriction.
I Consider a 6-out-of-10 threshold secret-sharing scheme. With the libraries above, the calling program can receive the shares of users {1, . . . , 5} (an unauthorized set) in one call to share, and then receive the shares of users {6, . . . , 10} in another call. It might seem like the calling program can then combine these shares to reconstruct the secret (if the same message was shared in both calls). However, this is not the case because these two sets of shares came from two independent executions of the Share algorithm. Shares generated by one call to Share should not be expected to function with shares generated by another call, even if both calls to Share used the same secret message.
I Recall that in our style of defining security using libraries, it is only the internal differences between the libraries that must be hidden. Anything that is the same between the two libraries need not be hidden. One thing that is the same for the two libraries here is the fact that they output the shares belonging to the same set of users U . This security definition does not require shares to hide which user they belong to. Indeed, you can modify a secret-sharing scheme so that each user’s identity is appended to his/her corresponding share, and the result would still satisfy the security definition above.
I Justliketheencryptiondefinitiondoesnotaddresstheproblemofkeydistribution, the secret-sharing definition does not address the problem of who should run the Share algorithm (if its input m is so secret that it cannot be entrusted to any sin- gle person), or how the shares should be delivered to the n different users. Those concerns are considered out of scope by the problem of secret-sharing (although we later discuss clever approaches to the first problem). Rather, the focus is simply on whether it is even possible to encode data in such a way that an unauthorized set of shares gives no information about the secret, while any authorized set completely reveals the secret.
An Insecure Approach
One way to understand the security of secret sharing is to see an example of an “obvious” but insecure approach for secret sharing, and study why it is insecure.
49

Draft: January 3, 2021 CHAPTER 3. SECRET SHARING
    M = {0, 1}500 t=5
n=5
Share(m):
splitmintom=s1∥···∥s5, Reconstruct(s1,...,s5):
where each |si | = 100 return s1 ∥ · · · ∥s5 return (s1, . . . , s5)
   Construction 3.4 (Insecure TSSS)
Let’s consider a 5-out-of-5 secret-sharing scheme. This means we want to split a secret into 5 pieces so that any 4 of the pieces leak nothing. One way you might think to do this is to literally chop up the secret into 5 pieces. For example, if the secret is 500 bits, you might give the first 100 bits to user 1, the second 100 bits to user 2, and so on.
It is true that the secret can be constructed by concatenating all 5 shares, and so this construction satisfies the correctness property. (The only authorized set is the set of all 5 users, so we write Reconstruct to expect all 5 shares.)
However, the scheme is insecure (as promised). Suppose you have even just 1 share. It is true that you don’t know the secret in its entirety, but the security definition (for 5- out-of-5 secret sharing) demands that a single share reveals nothing about the secret. Of course knowing 100 bits of something is not the same as than knowing nothing about it.
We can leverage this observation to make a more formal attack on the scheme, in the form of a distinguisher between the two Ltsss-⋆ libraries. As an extreme case, we can distinguish between shares of an all-0 secret and shares of an all-1 secret:
Let’s link this calling program to both of the Ltsss-⋆ libraries and see what happens:
When A is linked to Ltsss-L, it
receives a share of 0500, which
⋄ will itself be a string of all ze- roes. In this case, A outputs 1
with probability 1.
When A is linked to Ltsss-R, it
receives a share of 1500 which
⋄ will be a string of all ones. In this case, A outputs 1 with probabil-
ity 0.
We have constructed a calling program which behaves very differently (indeed, as differently as possible) in the presence of the two libraries. Hence, this secret-sharing scheme is not secure.
Hopefully this example demonstrates one of the main challenges (and amazing things) about secret-sharing schemes. It is easy to reveal information about the secret gradually as
   A
 s1 := share(0500, 1500, {1}) returns1 =? 0100
   Ltsss-L
 share(mL,mR,U):
if |U | > t: return err s ← Share( mL ) return{si |i∈U}
      A
 s1 := share(0500, 1500, {1}) returns1 =? 0100
       Ltsss-R
 share(mL,mR,U):
if |U | > t: return err s ← Share( mR ) return{si |i∈U}
      A
 s1 := share(0500, 1500, {1}) returns1 =? 0100
  50

Draft: January 3, 2021 CHAPTER 3. SECRET SHARING
 3.2
Construction 3.5 (2-out-of-2 TSSS)
Example
more shares are obtained, like in this insecure example. However, the security definition of secret sharing is that the shares must leak absolutely no information about the secret, until the number of shares passes the threshold value.
A Simple 2-out-of-2 Scheme
Believe it or not, we have already seen a simple secret-sharing scheme! In fact, it might even be best to think of one-time pad as the simplest secret-sharing scheme.
Since it’s a 2-out-of-2 scheme, the only authorized set of users is {1, 2}, so Reconstruct is written to expect both shares s1 and s2 as its inputs. Correctness follows easily from what we’ve already learned about the properties of xor.
If we want to share the string m = 1101010001 then the Share algorithm might choose
s1 := 0110000011 s2 :=s1 ⊕m
= 0110000011 ⊕ 1101010001 = 1011010010. Then the secret can be reconstructed by xoring the two shares together, via: s1 ⊕ s2 = 0110000011 ⊕ 1011010010 = 1101010001 = m.
Remember that this example shows just one possible execution of Share(1101010001), but Share is a randomized algorithm and many other values of (s1,s2) are possible.
Construction 3.5 is a secure 2-out-of-2 threshold secret-sharing scheme.
   M = {0,1}l t=2
n=2
Share(m):
s1 ← {0, 1}l
s2 :=s1 ⊕m return (s1,s2)
Reconstruct(s1, s2): returns1 ⊕s2
   Theorem 3.6
Proof
LΣ : tsss-L
Let Σ denote Construction 3.5. We will show that LΣ tsss-L
≡ LΣ using a hybrid proof. tsss-R
As usual, the starting point is LΣ , shown here with the
tsss-L
details of the secret-sharing scheme filled in (and the types of the subroutine ar- guments omitted to reduce clutter).
 LΣ tsss-L
 share(mL,mR,U):
if |U | > 2: return err
return{si |i∈U}
  s1 ←{0,1}l s2 :=s1 ⊕mL
    51

Draft: January 3, 2021
CHAPTER 3. SECRET SHARING
   share(mL,mR,U):
if |U | > 2: return err if U = {1}:
s1 ←{0,1}l s2 :=s1 ⊕mL return {s1}
elsif U = {2}: s1 ←{0,1}l
s2 :=s1 ⊕mL return {s2}
   else return ∅
   share(mL,mR,U):
if |U | > 2: return err if U = {1}:
s1 ←{0,1}l s2 := s1 ⊕ mR return {s1}
elsif U = {2}: s1 ←{0,1}l s2 :=s1 ⊕mL return {s2}
else return ∅
  share(mL,mR,U):
if |U | > 2: return err if U = {1}:
s1 ←{0,1}l s2 :=s1 ⊕mR return {s1}
elsif U = {2}:
return {s2} else return ∅
 s2 ← eavesdrop(mL,mR)
   LOTP ots-L
eavesdrop(mL,mR):
 k ← {0,1}l c := k ⊕ mL return c
   ⋄
It has no effect on the li- brary’s behavior if we dupli- cate the main body of the library into 3 branches of a new if-statement. The reason for doing so is that the scheme generates s1 and s2 differently. This means that our proof will eventu- ally handle the 3 different unauthorized sets ({1}, {2}, and ∅) in fundamentally dif- ferent ways.
The definition of s2 has been changed in the first if-branch. This has no effect on the library’s behavior since s2 is never actually used in this branch.
Recognizing the second
branch of the if-statement as
a one-time pad encryption
(of mL under key s1), we
factor out the generation
of s2 in terms of the library
LOTP from the one-time ots-L
secrecy definition. This has
no effect on the library’s
behavior. Importantly, the
subroutine in LOTP expects ots-L
two arguments, so that is what we must pass. We choose to pass mL and mR for reasons that should become clear very soon.
52

Draft: January 3, 2021
CHAPTER 3. SECRET SHARING
     share(mL,mR,U):
if |U | > 2: return err if U = {1}:
s1 ←{0,1}l s2 :=s1 ⊕mR return {s1}
elsif U = {2}:
s2 ← eavesdrop(mL,mR) return {s2}
else return ∅
   LOTP ots-R
eavesdrop(mL,mR):
 k ← {0,1}l c := k ⊕ mR return c
      Theorem 3.7
We in fact proved a slightly more general statement. The only property of one-time pad we used was its one-time secrecy. Substituting one-time pad for any other one-time secret encryption scheme would still allow the same proof to go through. So we actually proved the following:
If Σ is an encryption scheme with one-time secrecy, then the following 2-out-of-2 threshold secret-sharing scheme S is secure:
LΣ : tsss-R
share(mL,mR,U):
if |U | > 2: return err if U = {1}:
s1 ←{0,1}l s2 :=s1 ⊕mR return {s1}
elsif U = {2}:
return {s2} else return ∅
 s1 ←{0,1}l s2 :=s1 ⊕mR
 LΣ tsss-R
 share(mL,mR,U):
if |U | > 2: return err
  s1 ←{0,1}l
s2 :=s1 ⊕mR return{si |i∈U}
We showed that LΣ tsss-L
scheme is secure.
≡ Lhyb-1 ≡ · · · ≡ Lhyb-5 ≡ LΣ tsss-R
, and so the secret-sharing

⋄
WehavereplacedLOTP with ots-L
LOTP . From the one-time se- ots-R
crecy of one-time pad (and the composition lemma), this change has no effect on the library’s behavior.
A subroutine has been in- lined; no effect on the li- brary’s behavior.
The code has been sim-
plified. Specifically, the
branches of the if-statement
can all be unified, with no ef-
fect on the library’s behav-
ior. The result is LΣ . tsss-R
 53

Draft: January 3, 2021 CHAPTER 3. SECRET SHARING
    M = Σ.M t=2
n=2
Share(m):
s1 ← Σ.KeyGen
s2 ← Σ.Enc(s1,m) return (s1,s2)
Reconstruct(s1,s2): return Σ.Dec(s1,s2)
   Theorem 3.8 (Poly Interpolation)
Proof
3.3
Polynomial Interpolation
You are probably familiar with the fact that two points determine a line (in Euclidean geometry). It is also true that 3 points determine a parabola, and so on. The next secret- sharing scheme we discuss is based on the following principle:
d + 1 points determine a unique degree-d polynomial.
A note on terminology: If f is a polynomial that can be written as f(x) = Ídi=0 fixi, then we say that f is a degree-d polynomial. It would be more technically correct to say that the degree of f is at most d since we allow the leading coefficient fd to be zero. For convenience, we’ll stick to saying “degree-d” to mean “degree at most d.”
Polynomials Over the Reals
Let {(x1,y1), . . . , (xd+1,yd+1)} ⊆ R2 be a set of points whose xi values are all distinct. Then there is a unique degree-d polynomial f with real coefficients that satisfies yi = f (xi ) for alli.
To start, consider the following polynomial:
l1(x) = (x −x2)(x −x3)···(x −xd+1) .
(x1 −x2)(x1 −x3)···(x1 −xd+1)
The notation is potentially confusing. l1 is a polynomial with formal variable x (written in bold). The non-bold xi values are just plain numbers (scalars), given in the theorem statement. Therefore the numerator in l1 is a degree-d polynomial in x . The denominator is just a scalar, and since all of the xi ’s are distinct, we are not dividing by zero. Overall, l1 is a degree-d polynomial.
What happens when we evaluate l1 at one of the special xi values?
I Evaluating l1(x1) makes the numerator and denominator the same, so l1(x1) = 1. I Evaluatingl1(xi)fori ,1leadstoaterm(xi −xi)inthenumerator,sol1(xi)=0.
Of course, l1 can be evaluated at any point (not just the special points x1,...,xd+1), but we don’t care about what happens in those cases.
We can similarly define other polynomials lj :
lj(x) = (x −x1)···(x −xj−1)(x −xj+1)···(x −xd+1) .
(xj −x1)···(xj −xj−1)(xj −xj+1)···(xj −xd+1)
The pattern is that the numerator is “missing” the term (x − x j ) and the denominator is
missingtheterm(xj −xj),becausewedon’twantazerointhedenominator.Polynomials 54
  
Draft: January 3, 2021 CHAPTER 3. SECRET SHARING
 of this kind are called LaGrange polynomials. They are each degree-d polynomials, and they satisfy the property:
(1 ifi=j 0 ifi,j
Now consider the following polynomial:
f (x) = y1l1(x) + y2l2(x) + · · · + yd+1ld+1(x).
Note that f is a degree-d polynomial since it is the sum of degree-d polynomials (again, the yi values are just scalars).
What happens when we evaluate f on one of the special xi values? Since li (xi ) = 1 andlj(xi)=0forj ,i,weget:
f (xi ) = y1l1(xi ) + · · · + yi li (xi ) + · · · + yd+1ld+1(xi ) =y1 ·0+···+yi ·1+···+yd+1 ·0
=yi
So f (xi ) = yi for every xi , which is what we wanted. This shows that there is some degree-d polynomial with this property.
Now let’s argue that this f is unique. Suppose there are two degree-d polynomials f and f ′ such that f (xi ) = f ′(xi ) = yi for i ∈ {1, . . . , d + 1}. Then the polynomial д(x) = f (x) − f ′(x) also is degree-d, and it satisfies д(xi ) = 0 for all i. In other words, each xi is a root of д, so д has at least d + 1 roots. But the only degree-d polynomial with d + 1 roots is the identically-zero polynomial д(x) = 0. If д(x) = 0 then f = f ′. In other words, any degree-d polynomial f ′ that satisfies f ′(xi ) = yi must be equal to f . So f is the unique polynomial with this property. 
Example Let’s figure out the degree-3 polynomial that passes through the points (3, 1), (4, 1), (5, 9), (2, 6):
i1234 xi 3 4 5 2 yi 1 1 9 6
First, let’s construct the appropriate LaGrange polynomials:
l1(x)= (x−x2)(x−x3)(x−x4) =(x−4)(x−5)(x−2)=x3−11x2+38x−40 (x1 −x2)(x1 −x3)(x1 −x4) (3−4)(3−5)(3−2) 2
l2(x)= (x−x1)(x−x3)(x−x4) =(x−3)(x−5)(x−2)=x3−10x2+31x−30 (x2 −x1)(x2 −x3)(x2 −x4) (4−3)(4−5)(4−2) −2
l3(x)= (x−x1)(x−x2)(x−x4) =(x−3)(x−4)(x−2)=x3−9x2+26x−24 (x3 −x1)(x3 −x2)(x3 −x4) (5−3)(5−4)(5−2) 6
l4(x)= (x−x1)(x−x2)(x−x3) =(x−3)(x−4)(x−5)=x3−12x2+47x−60 (x4 −x1)(x4 −x2)(x4 −x3) (2−3)(2−4)(2−5) −6
lj(xi) =
             55

Draft: January 3, 2021 CHAPTER 3. SECRET SHARING
 As a sanity check, notice how:
l1(x1)=l1(3)= 33 −11·32 +38·3−40 = 2 =1 22
l1(x2)=l1(4)= 43 −11·42 +38·4−40 = 0 =0 22
It will make the next step easier if we rewrite all LaGrange polynomials to have the same denominator 6:
l1(x) = 3x3 − 33x2 + 114x − 120 l3(x) = x3 − 9x2 + 26x − 24 66
l2(x) = −3x3 + 30x2 − 93x + 90 l4(x) = −x3 + 12x2 − 47x + 60 66
      Our desired polynomial is
f(x)=y1 ·l1(x)+y2 ·l2(x)+y3 ·l3(x)+y4 ·l4(x) = 1 · l1(x) + 1 · l2(x) + 9 · l3(x) + 6 · l4(x)
1 ·   3x3 − 33x2 + 114x − 120
1© +1· −3x3 +30x2 −93x +90 a =­ 32 ® 6­ +9· x −9x +26x −24 ®
+6·  −x3 +12x2 −47x +60 1«¬
3x3 − 12x2 − 27x + 114
=
=
And indeed, f gives the correct values:
16
14
12 22
10 43 29·4 8 f(x2)=f(4)= −2·4 − 622
6
x3 2 9x −2x− +19
22
  (5,9)
(2,6)
(3,1) (4,1)
     4 53 29·5 f(x3)= f(5)= −2·5 −
222
0 23 29·2 0 1 2 3 4 5 6 f(x4)=f(2)= −2·2 −
Polynomials mod p
f(x1)= f(3)=
33 29·3 −2·3 −
+19=1=y1 +19=1=y2 +19=9=y3 +19=6=y4
We will see a secret-sharing scheme based on polynomials, whose Share algorithm must choose a polynomial with uniformly random coefficients. Since we cannot have a uniform distribution over the real numbers, we must instead consider polynomials with coefficients in Zp .
It is still true that d + 1 points determine a unique degree-d polynomial when working modulo p, if p is a prime!
56
22

Draft: January 3, 2021 CHAPTER 3. SECRET SHARING
 
Theorem 3.9 (Interp mod p)
Letpbeaprime,andlet{(x1,y1),...,(xd+1,yd+1)}⊆ (Zp)2beasetofpointswhosexival- ues are all distinct. Then there is a unique degree-d polynomial f with
thatsatisfiesyi ≡p f(xi)foralli.
The proof is the same as the one for Theorem 3.8, if you interpret all arithmetic modulo p. Addition, subtraction, and multiplication mod p are straight forward; the only non- trivial question is how to interpret “division mod p,” which is necessary in the definition of the lj polynomials. For now, just accept that you can always “divide” mod p (except by zero) when p is a prime. If you are interested in how division mod p works, look ahead to Chapter 13.
We can also generalize the observation that d + 1 points uniquely determine a degree-d polynomial. It turns out that:
For any k points, there are exactly pd+1−k polynomials of degree-d that hit those points, mod p.
Note how when k = d + 1, the statement says that there is just a single polynomial hitting the points.
LetP={(x1,y1),...,(xk,yk)}⊆(Zp)2beasetofpointswhosexi valuesaredistinct.Letd satisfy k 6 d + 1 and p > d. Then the number of degree-d polynomials f with coefficients in Zp that satisfy the condition yi ≡p f (xi ) for all i is exactly pd +1−k .
Theproofisbyinductiononthevalued+1−k.Thebasecaseiswhend+1−k=0.Then we have k = d + 1 distinct points, and Theorem 3.9 says that there is a unique polynomial satisfying the condition. Since pd+1−k = p0 = 1, the base case is true.
For the inductive case, we have k 6 d points in P. Let x∗ ∈ Zp be a value that does not appear as one of the xi ’s. Every polynomial must give some value when evaluated at x∗. So,
[# of degree-d polynomials passing through points in P]
= Õ [# of degree-d polynomials passing through points in P ∪ {(x∗,y∗)}]
 Corollary 3.10 (# of polys)
Proof
y∗∈Zp
(⋆) Õ d +1−(k +1)
=p y∗∈Zp
= p · pd+1−k−1 = pd+1−k
The equality marked (⋆) follows from the inductive hypothesis, since each of the terms involves a polynomial passing through a specified set of k + 1 points with distinct x-
coordinates.